{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a26aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0052e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6406794",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "How to explain ;\n",
    "\n",
    "\n",
    "\n",
    "1 )\n",
    "\n",
    "2 ) data collection , sources of data , talk about data engineer & Big data eng \n",
    "\n",
    "3 ) data preprocessing  , then data-preprocessing(2)\n",
    "\n",
    "4 ) \n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfa710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b7511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4ed02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b8dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be7e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60507424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "GenAI isn't just:\n",
    "\n",
    "\"U can Use a GenAI models or LLMs and get output\"\n",
    "So here we will learn whole life cycle of GenAI project which is applicable to any GenAI project :\n",
    "\n",
    "It‚Äôs actually pipeline involving :\n",
    "\n",
    "\n",
    "Understanding use-case\n",
    "Gathering data \n",
    "Cleaning data \n",
    "Choosing Right GenAI Model\n",
    "Model Adaptation & Alignment\n",
    "Deploying it \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e21e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd848c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a72697",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "One line summary :\n",
    "\n",
    "Business ‚Üí Data ‚Üí Preprocessing ‚Üí Model ‚Üí RAG/Inference ‚Üí Evaluation ‚Üí Deployment\n",
    "\n",
    "            OR\n",
    "\n",
    "\n",
    "Understanding Use-case ‚Üí Data Collection ‚Üí Data Preprocessing ‚Üí Choose right Model ‚Üí Fine Tuning ‚Üí Evaluation ‚Üí Deployment \n",
    "\n",
    "\n",
    "            OR \n",
    "\n",
    "\n",
    "Understanding Use-case ‚Üí Data Collection ‚Üí Data Preprocessing ‚Üí Choose right Model ‚Üí \n",
    "Model Alignment & Adaptation(Prompting/RAG/Fine-Tuning/Training with Human feedback) ‚Üí Deployment ‚Üí \n",
    "Model Optimization & Monitoring\n",
    "\n",
    "\n",
    "\n",
    "Understanding Use-case ‚Üí Data Collection ‚Üí Data Preprocessing ‚Üí Choose right Model ‚Üí \n",
    "Model Alignment & Adaptation ‚Üí Deployment ‚Üí \n",
    "Model Optimization & Monitoring\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a703c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394efcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed849870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8aaa34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cca942",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "üîç 1.. Understanding Use-case\n",
    "\n",
    "\n",
    "\n",
    "Client / Stakeholder ‚Üí Product Owner (or GenAI Product Manager) ‚Üí business analyst ‚Üí data team ‚Üí project requirements.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "üí° Example\n",
    "\n",
    "Client will go on conversation with Product Owner + Business Analyst of that company  , & they will try to gather requirements\n",
    "for the Project !\n",
    "\n",
    "‚úîÔ∏è Step 1: Client/Stakeholder will Define problem\n",
    "    Imagine A popular clothing store (like H&M or Zara) gets a lot of repetitive customer questions, such as:\n",
    "    ‚ÄúDo you have this shirt in Medium?‚Äù\n",
    "    ‚ÄúWhat jeans would look good with this jacket?‚Äù\n",
    "    ‚ÄúAre there any discounts today?‚Äù\n",
    "    ‚ÄúIs this available in store near me?‚Äù\n",
    "    \n",
    "\n",
    "    \n",
    "    Customers get frustrated because:\n",
    "\n",
    "    Staff are busy\n",
    "    Replies are slow\n",
    "    \n",
    "    \n",
    "    The store owner wants an AI assistant on their website + app that can answer these questions instantly..\n",
    "    here Store Owner is a client ( so client is someone who is facing some problem & they wants to get it solved)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "‚úîÔ∏è Step 2: Product Owner or GenAI Product Manager\n",
    "\n",
    "    Turns this problem into a clear product vision :\n",
    "    ‚ÄúLet‚Äôs build a fashion assistant that recommends outfits, checks stock, and suggests alternatives.‚Äù\n",
    "    \n",
    "    Product Owner is someone who will understand Client needs & then set Goals & priorities for AI & data Team !\n",
    "    Product Onwer is actually responsible to deliver right product/soln to client..\n",
    "    \n",
    "    Defines what AI should do:\n",
    "\n",
    "    Answer product questions\n",
    "    Suggest matching outfits\n",
    "    Check size availability\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "‚úîÔ∏è Step 3: Business Analyst\n",
    "\n",
    "    Translates goals into clear requirements:\n",
    "            OR\n",
    "    Converts Business needs into technical needs so that our AI & data team(GenAI eng , GenAI Architect , Data Eng)\n",
    "    can actually work..\n",
    "\n",
    "    Collect product catalog (name, size, color, fabric, price)\n",
    "    Support ‚Äústyle recommendation‚Äù\n",
    "    Handle simple inventories\n",
    "    Friendly, fashion-oriented tone\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "‚úîÔ∏è Step 4: Data + AI Team\n",
    "\n",
    "    To build the system , they need data so all these requirements are sent to Data & AI team \n",
    "    (Data Scientist , Data Eng , AI eng , Big Data Eng) & they will ask to Client , PO & BA regarding source of data !\n",
    "    eg from where they have to collect data (3rd Part APIs , websites , PDFs , Documents  , DBs , Big Data Sources )\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bb2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59dd97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5eaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1900fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "üì• 2.. Data Collection :\n",
    "\n",
    "\n",
    "    In GenAI , you don‚Äôt always need external data bcz some GenAI projects can work entirely with the model‚Äôs knowledge + prompts..\n",
    "    If your GenAI app is doing generic tasks like Summarize articles , writing simple code , you do not need data !\n",
    "    Bcz these Large models like GPT, Gemini, LLaMA are trained on massive amounts of Internet data, so they already know :\n",
    "\n",
    "    how to summarize text\n",
    "    how to write emails or code , \n",
    "\n",
    "    so if u will ask those models any general question + good prompt , u are done !\n",
    "\n",
    "\n",
    "\n",
    "    But many real-world projects do need data to ground the model in your business context...\n",
    "    Bcz model does not know your business by default..\n",
    "    These tasks require data like :\n",
    "\n",
    "    What size shirts do we have in stock\n",
    "    What is last week‚Äôs sales report\n",
    "    What is our latest discount\n",
    "\n",
    "    These require your own data, because here model does not know your business..\n",
    "\n",
    "\n",
    "    Data collection will give us raw data ( ie this data can have typos, can be unstructured)\n",
    "    u have to make it structured so that GenAI models can accept this data \n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff2633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea475099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69107276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34786e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88017091",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "üßπ 3.. Data Preprocessing :\n",
    "        Data preprocessing means converting raw data into prepared data or pre-processed data so that \n",
    "        GenAI models can understand your query & generate output for you !\n",
    "        \n",
    "        \n",
    "        Cleaning the text\n",
    "            Remove HTML tags\n",
    "            Fix typos\n",
    "            Remove irrelevant sections\n",
    "            Normalize formatting\n",
    "                    OR\n",
    "            u can clean above stuff using LLMs..\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        Store Data in Vector Database\n",
    "            U can think of Storing Data in Vector Database so that we can do Fast retrieval based on meaning, not exact match..\n",
    "            Examples:\n",
    "\n",
    "                ChromaDB - beginner-friendly\n",
    "                Pinecone - cloud-based & scalable\n",
    "                FAISS - fast & local\n",
    "                \n",
    "                \n",
    "            üß† Simple Example\n",
    "\n",
    "            User asks:\n",
    "            ‚ÄúDo you have medium size shirts?‚Äù\n",
    "\n",
    "            but in database you have :\n",
    "            ‚Äú11 Shirts available in size M‚Äù\n",
    "\n",
    "            A vector database understands that ‚ÄúMedium‚Äù = ‚ÄúM‚Äù will return you all 11 medium size tshirts..\n",
    "            That‚Äôs why it‚Äôs better than normal or traditional databases.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Embedding Generation\n",
    "        Embeddings are a way to convert text into numbers so AI Models can understand the meaning of the text..\n",
    "        \n",
    "            üìå Why embeddings ?\n",
    "            Because LLMs can't \"search\" plain text ‚Äî they search meaning, not words..\n",
    "            \n",
    "            üß† Simple Example\n",
    "\n",
    "            ‚ÄúMedium size shirt‚Äù\n",
    "            ‚ÄúSize M shirt‚Äù\n",
    "            \n",
    "            ‚ÄúMedium size shirt‚Äù  ‚Üí  [0.12, 0.45, 0.78, ...]\n",
    "            ‚ÄúSize M shirt‚Äù       ‚Üí  [0.11, 0.46, 0.77, ...]\n",
    "            \n",
    "            U will see the numbers are very similar..\n",
    "            ‚≠ê What does this tell the AI?\n",
    "\n",
    "                Different word\n",
    "                Same meaning\n",
    "                Similar embeddings\n",
    "\n",
    "                So the AI understands that both sentences are related.\n",
    "\n",
    "\n",
    "        \n",
    "            So Embedding Convert text into vector representations that capture meaning.\n",
    "            Used for:\n",
    "\n",
    "            RAG\n",
    "            Search\n",
    "            Similarity\n",
    "            Clustering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        üñºÔ∏è Image Preprocessing (if vision involved)\n",
    "            If your project uses images, you can't directly use GenAI Models :\n",
    "            Bcz LLMs mainly understand text, not image , video or audio..\n",
    "            \n",
    "            Now now u may ask , When you upload an image to ChatGPT or any LLM like Gemini , LLama, etc , \n",
    "            they will return u some output !\n",
    "            But how ?\n",
    "            \n",
    "            Ans : They does NOT understand image directly.\n",
    "                   Instead, it runs a pipeline internally..\n",
    "            \n",
    "            Lets consider a real world example :\n",
    "            \n",
    "            If u will upload any image to chatGPT or any LLM & say hey tell me calories in this food image ?\n",
    "            ChatGPT or Gemini or any Text-based LLMs will not be able to answer it correctly , \n",
    "            \n",
    "            \n",
    "            First, Vision Model understands the image(ie extract food name with serving size)\n",
    "                eg ‚ÄúA bowl of rice with vegetables, medium serving‚Äù\n",
    "            Then above text is passed to an LLM.\n",
    "            Then LLM will generate calorie report or Nutrition summary..\n",
    "            \n",
    "\n",
    "            Image\n",
    "              ‚Üì\n",
    "            Vision Model like BLIP / CLIP \n",
    "              ‚Üì\n",
    "            Text Description\n",
    "              ‚Üì\n",
    "            LLM\n",
    "              ‚Üì\n",
    "            Final Answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        üîä Audio Preprocessing (if audio involved)\n",
    "            Similarly If your GenAI project has audio input, you cannot directly send raw audio to a text-based LLM or GenAI models..\n",
    "            Bcz LLMs mainly understand text, not raw audio..\n",
    "            So first, you must convert audio into text.\n",
    "            \n",
    "            ü§î Then why can ChatGPT / Gemini accept audio ?\n",
    "            \n",
    "                See When you upload an audio file to ChatGPT or any LLM like Gemini , LLama, \n",
    "                they does NOT understand raw audio directly.\n",
    "                Instead, system runs a pipeline internally..\n",
    "\n",
    "            \n",
    "            Lets consider a real world example :\n",
    "            Imagine u have to generate meeting summary of 1 hour team meeting Audio call where People were discussing:\n",
    "\n",
    "            project deadlines\n",
    "            tasks\n",
    "            blockers\n",
    "\n",
    "            So if u upload audio file to ChatGPT or LLM , LLMs will pre-process this raw audio..\n",
    "            ie first it will extract text from Audio & text will sent to LLM !\n",
    "            \n",
    "            üîÅ Audio Preprocessing Steps\n",
    "\n",
    "                1Ô∏è‚É£ Noise Removal\n",
    "                Remove fan noise, background chatter\n",
    "\n",
    "                2Ô∏è‚É£ Speech-to-Text (STT)\n",
    "                Convert meeting audio ‚Üí text transcript\n",
    "\n",
    "                3Ô∏è‚É£ Speaker Identification (optional)\n",
    "                ‚ÄúManager said this‚Äù\n",
    "                ‚ÄúDeveloper said that‚Äù\n",
    "            \n",
    "\n",
    "            Why to do Audio Preprocessing?\n",
    "            Extract text from audio so that LLM will generate \n",
    "\n",
    "                Meeting summary\n",
    "                Action items\n",
    "                Deadlines\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            Audio\n",
    "              ‚Üì\n",
    "            Audio Preprocessing \n",
    "              ‚Üì\n",
    "            Text\n",
    "              ‚Üì\n",
    "            LLM\n",
    "              ‚Üì\n",
    "            Structured Output (ie Meeting summary)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2213553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f9cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cc653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "üß† 4.. Choose right model :\n",
    "        There are 2 ways to choose right model :\n",
    "            \n",
    "        I ) Foundation Models\n",
    "            LLaMA\n",
    "            GPT\n",
    "            Gemini\n",
    "            Claude\n",
    "            DeepSeek\n",
    "            BLIP (for vision)\n",
    "            \n",
    "            üëâ Usually 90% of practical projects use foundation models..\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        II) Custom LLM\n",
    "            A Custom LLM means building your own AI model or LLM from scratch, or taking an existing model and changing it a lot, \n",
    "            so it behaves exactly how you want..\n",
    "                    OR\n",
    "            Build specialized models or LLMs from scratch , mostly for enterprise or research\n",
    "            You do this when you need:\n",
    "            \n",
    "            Very specific behavior\n",
    "            e.g., a medical AI that writes reports exactly like doctors\n",
    "\n",
    "            Special expert knowledge\n",
    "            e.g., an AI trained only on your company‚Äôs confidential documents\n",
    "            \n",
    "\n",
    "\n",
    "            üëâ Usually 90% of practical projects use foundation models.. , then \n",
    "            ‚ö†Ô∏è Why Custom LLMs are rare ? \n",
    "\n",
    "            Because they are:\n",
    "\n",
    "            Very expensive\n",
    "            Require huge datasets\n",
    "            Need powerful GPUs\n",
    "            Need ML researchers + engineers\n",
    "            Take months to build\n",
    "\n",
    "            That‚Äôs why they are mostly built by:\n",
    "\n",
    "            Big enterprises\n",
    "            Research labs\n",
    "            AI companies (OpenAI, Google, Meta)\n",
    "\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2800c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e670a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932639ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9dffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "üéØ 5.. Model Alignment & Adaptation(Prompting/RAG/Fine-Tuning/Training with Human feedback) :\n",
    "        Improve model behavior via Prompting, RAG, Fine-Tuning, Training with Human feedback..\n",
    "        \n",
    "        It has 4 major parts:\n",
    "\n",
    "        1. Prompt Engineering\n",
    "            Use smart prompts to improve output Quality of LLMs\n",
    "    \n",
    "    \n",
    "        2. ‚≠ê RAG \n",
    "\n",
    "            R = Retrieval stage\n",
    "            You have to retrieve/extract factual data from external sources like documents, DB, PDFs, website..\n",
    "\n",
    "\n",
    "            A = Augmentation Stage\n",
    "            You insert the retrieved data(factual data) into the LLM prompt:\n",
    "            ie , You are augmenting/injecting/sending verified data to LLM..\n",
    "            So now , the model has correct data before generating output\n",
    "\n",
    "\n",
    "            G = Generation Stage\n",
    "            The LLM generates final structured data based on the augmented data + User Query !\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        3. Fine-Tuning\n",
    "\n",
    "            Fine-tuning is the process of improving a base model so it performs better on your specific task..\n",
    "            But nowadays , Prompt engineering + Modern LLMs or Modern Models are capable enough that u don't need Fine tuning \n",
    "            for most of the real-world applications !\n",
    "\n",
    "            But Fine Tuning is still valuable when you need high accuracy..\n",
    "            Fine Tuning actually works by modifying the model‚Äôs internal parameters (weights) so it learns new patterns such as:\n",
    "\n",
    "            New knowledge\n",
    "            Domain context\n",
    "            Output style\n",
    "\n",
    "\n",
    "\n",
    "            üü£ Why & when Do We need Fine-Tune ?\n",
    "            Ans : Base models or LLMs (Gemini, ChatGPT, LLaMA) are general-purpose and not optimized for any one domain..\n",
    "            If you want domain-specific results, fine-tuning helps the model:\n",
    "\n",
    "            a) Perform a specific task more accurately\n",
    "            b) Understand domain-specific language (medical, legal, finance, technical, etc.)\n",
    "            c) Produce consistent, controlled outputs\n",
    "\n",
    "\n",
    "            I. Supervised Fine-Tuning (SFT)\n",
    "\n",
    "            Training the model on labeled examples:\n",
    "            Input ‚Üí Desired Output\n",
    "            We will give Many examples & model learns the pattern\n",
    "\n",
    "\n",
    "            II. PEFT / LoRA\n",
    "\n",
    "            (Low-Rank Adaptation)\n",
    "            More efficient version of fine-tuning\n",
    "            Only updates small parts of the model\n",
    "\n",
    "            Faster and cheaper\n",
    "\n",
    "\n",
    "            üîπ Why You Often Don‚Äôt Need It\n",
    "\n",
    "            Many use-cases do not require fine-tuning because:\n",
    "\n",
    "            Prompt engineering can solve the problem\n",
    "            RAG can provide domain knowledge without training\n",
    "            Fine-tuning is expensive and complex\n",
    "            Models are already extremely capable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        4. Training with Human Feedback\n",
    "            Bcz it helps LLMs behave in a more useful, safe, and human-like way.\n",
    "\n",
    "            We will train with Human Feedback so that :\n",
    "            a ) Our LLM output/response Align with human values\n",
    "                (be polite, helpful, and ethical)\n",
    "\n",
    "            b ) Reduce hallucinations\n",
    "                (avoid making up false or harmful information)\n",
    "            ‚ö†Ô∏è Training with human feedback is complex, expensive, and rarely used in small projects..\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            Summary : Start with Prompting + RAG, fine-tune only if needed..\n",
    "                      & use Training with Human Feedback in large-scale systems only..\n",
    "\n",
    "\n",
    "\n",
    "            üîë Rule of Thumb (Very Important for Students)\n",
    "\n",
    "                big companies always start with a Foundation Model/LLMs like ChatGPT , Gemini  , Cluade etc..\n",
    "                If needed then they model behavior by using prompts + RAG + fine-tuning & if it fails then they Move to Custom LLM..\n",
    "  \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f515095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2faccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "üöÄ 6.. Model Deployment : \n",
    "    \n",
    "        Deploy your Model so that end-users can use this model in a real application..\n",
    "\n",
    "        Streamlit : simple web app for users to interact with the model\n",
    "        FastAPI backend ‚Äî API that connects your model to apps or services\n",
    "        HuggingFace Spaces ‚Äî free hosting for AI apps\n",
    "        Containers & GPUs ‚Äî run your app on cloud servers at scale\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    Model Optimization & Monitoring :\n",
    "    \n",
    "\n",
    "    üîÅ After Deployment (What you do next)\n",
    "    Once the app is live, you should do Model Optimization & Monitoring..\n",
    "\n",
    "    Monitor how users interact\n",
    "    Optimize performance & cost\n",
    "    Improve the app based on user feedback\n",
    "    \n",
    "    \n",
    "    \n",
    "    ‚≠ê Why Optimization Matters After Deployment\n",
    "    Because when you deploy a model, you must make decisions that affect speed, cost, and scalability :\n",
    "\n",
    "    Quantization ‚Äî make the model smaller to save resources\n",
    "    Acceleration (GPU/TPU) - How fast will it respond?\n",
    "    Cost optimization - How much will it cost per request?\n",
    "    How to scale to 1000 users?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c96a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad665542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8b8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131605f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
