{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c656c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd1bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffa392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725a851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Scenario 1: Business Relationship (Service Industry)\n",
    "\n",
    "        TCS is selling services\n",
    "        Nike is buying services\n",
    "\n",
    "        So:\n",
    "        In the market, Nike is the client of TCS.\n",
    "\n",
    "\n",
    "Scenario 2: GenAI Product Development (Our Case Study)\n",
    "\n",
    "        We are building an app for:\n",
    "        TCS Sales Team (or Accenture, Infosys, Deloitte)\n",
    "\n",
    "        So:\n",
    "\n",
    "        For us (the GenAI builders)\n",
    "        TCS is the client\n",
    "\n",
    "        NOT Nike\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d621ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866ac9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db57ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Client:\n",
    "â€œOther companies are hiring ML engineers, so we also want to pitch our services to them.â€\n",
    "â€œso Nike , JPMorgan , Walmart are Clientsâ€\n",
    "\n",
    "Product Owner:\n",
    "â€œWe need personalized cold emails based on each job post to win projects.â€\n",
    "\n",
    "Business Analyst:\n",
    "â€œWe need job data, skill extraction, company details, and email templates etc.. â€\n",
    "\n",
    "Data Team:\n",
    "â€œScrape job posts, clean text, chunk content, create embeddings.â€\n",
    "\n",
    "GenAI Developer:\n",
    "â€œBuild scraping pipeline, vector DB, prompts, and Streamlit UI.â€\n",
    "\n",
    "GenAI Architect:\n",
    "â€œLet's use LLaMA + vector DB to extract skills and generate emails.â€\n",
    "\n",
    "QA Team:\n",
    "â€œCheck tone, grammar, personalization, and ensure no wrong info.â€\n",
    "\n",
    "LLMOps:\n",
    "â€œDeploy app, monitor usage, optimize performance & GPU cost.â€\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfc62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c008b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12977ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "âœ”ï¸ Super Short Version (one-liner) : \n",
    "\n",
    "Cold email generator = Structured Job Posting data + Extract Relevant Portfolio links from ChromaDB + Generate\n",
    "                        Cold Email using LLM + prompt..\n",
    "\n",
    "\n",
    "Cold email generator = Structured Job data  + Portfolio links from ChromaDB + LLM with prompt\n",
    "                        ie from structured Job posting data , we will extract relevant Portfolio links from ChromaDB & then using \n",
    "                        LLM with prompt , we will write an cold email..\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14463619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a26b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c2588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93b9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ae7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we will build end-2-end LLM Project called cold email generator using Llama 3.1 (open source LLM)\n",
    "\n",
    "'''\n",
    "\n",
    "we will use chroma-DB vector store & langchain & streamlit \n",
    "\n",
    "\n",
    "chroma db is a very light weight db [ Pls understand what is vector db ( check codebasic vector db video )]\n",
    "Que is : Why we are not using traditional(SQL) db , why we are using this special db(vector db) ?\n",
    "\n",
    "langchain is a python package/framework which helps u to build LLM app easier \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e321bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f76ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac090f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e33e3c16",
   "metadata": {},
   "source": [
    "### Introduction to Business problem !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0734978f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLets understand the problem statement first :\\n\\n\\nThere are service based companies like Infosys , TCS & they have their client like Nike , JPMorganetc.. & service \\nbased companies builds softwares for these companies\\n\\n\\nThere is lot of competition in this market..\\n\\nSo sales team of these service based companies use variety of marketing techniques to build & acquire projects..\\nOne of the technique is \"Cold Email\"\\n\\n\\n\\nWhat is \"cold Email\"?\\n\\nA person from service based companies(TCS) will send a cold email to their clients regarding softwares they are planning to build..\\nBut how he will get to know what type of software that company want..\\n\\n\\nOne way is : Go to their Job Portal & look into Projects & let say they have a requirement in AI/ML eng ..\\n\\nso what a TCS will do is :\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Lets understand the problem statement first :\n",
    "\n",
    "\n",
    "There are service based companies like Accenture , Deloitte , Infosys , TCS & they have their client like Nike ,JPMorgan etc.. \n",
    "& service based companies builds softwares for these ..\n",
    "\n",
    "\n",
    "There is lot of competition in this market..\n",
    "\n",
    "So sales team of these service based companies use variety of marketing techniques to build & acquire projects..\n",
    "One of the technique is \"Cold Email\"\n",
    "\n",
    "\n",
    "\n",
    "What is \"cold Email\"?\n",
    "\n",
    "A person from service based companies(TCS) will send a cold email to their clients regarding softwares they are planning to build..\n",
    "But how he will get to know what type of software that company want..\n",
    "\n",
    "\n",
    "One way is : Go to their Job Portal & look into Projects & let say they have a requirement in AI/ML eng ..\n",
    "\n",
    "so what a TCS sales representative folk will do is :\n",
    "he will send a cold email , hey it looks like u need a software/AI-ML eng & we have people here !\n",
    "So instead of hiring full time , u can hire from us \n",
    "\n",
    "& many times , this technique works !\n",
    "\n",
    "\n",
    "\n",
    "So BDE(Business Development Executive) at TCS/Infosys will have to form/create nice email which is relevant to the Job Post & \n",
    "one of the things we can use is GenAI !\n",
    "\n",
    "\n",
    "\n",
    "So in tool or App , what I will do is :\n",
    "I will paste job post URL & click on Submit !\n",
    "\n",
    "\n",
    "So when I will click on submit , it will go to that Job post  , it will figure out what all skills are needed &\n",
    "based on that , it will write an email..\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fff3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show quick overview of app so that people will have a interest !\n",
    "\n",
    "\n",
    "### Then explain above stuff !\n",
    "### Then show App UI & its working !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885fa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008c882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93b5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17712f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0c96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "325c1ad1",
   "metadata": {},
   "source": [
    "### Project Architecture Explained !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81eaedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "ğŸ§© Explain to Students (Simple Words)\n",
    "\n",
    "Step 1: First, we understand what the company wants (skills).\n",
    "Step 2: Then we show our relevant work (portfolio projects).\n",
    "Step 3: Finally, the LLM writes a convincing, personalized cold email using skills + portfolio projects \n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f668b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "## In terms of Career architecture :\n",
    "\n",
    "Once I will click on this submit button , we will go to that URL(JOb post URL) , \n",
    "extract text from that page using langchain framework\n",
    "\n",
    "Then we will use Llama 3.1 to extract Job skills/roles/description & store stuff in a json format :\n",
    "\n",
    "job = \n",
    "{\n",
    " \"role\" : \"Senior Software Engineer\" , \n",
    " \"skills\" : [ 2 years experience in React]\n",
    " \"description\" : we are looking for a -----\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "In chromaDB which is a vector database , we have previously stored the skills and\n",
    "the relevant portfolios of company..\n",
    "\n",
    "ie , \n",
    "\n",
    "\"Python\" : \"www.tcs.com/Python\" (Such time of stuffs are stored at VectorDB)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "then to LLM , we will give job description or skills + from chroma db , it will extract relevant Portfolio Links\n",
    "as well to generate cold email..\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ğŸ§¾ Summary (Simple)\n",
    "\n",
    "1 ) User enters a job posting URL and clicks submit\n",
    "2 ) App scrapes the page and extracts text\n",
    "3 ) LLaMA converts the raw text into structured JSON (role, skills, description)\n",
    "4 ) We have Portfolio data already stored in ChromaDB (Vector Database)\n",
    "5 ) We will use the job skills to run similarity search in ChromaDB\n",
    "6 ) ChromaDB returns the most relevant portfolio links\n",
    "7 ) LLM uses:\n",
    "    job description\n",
    "    relevant portfolio links to generate a personalized cold email\n",
    "\n",
    "\n",
    "\n",
    "    ğŸ§  Cold Email Generator â€“ Simple Flow\n",
    "\n",
    "    From Job Posting Data\n",
    "    â†’ extract skills the company is looking for\n",
    "\n",
    "    From those skills\n",
    "    â†’ fetch relevant portfolio links from ChromaDB\n",
    "\n",
    "    Then use LLM + Prompt\n",
    "    â†’ generate a personalized cold email\n",
    "\n",
    "    Scrap job description â†’ extract skills â†’ find matching portfolio links as per skills â†’ generate cold email using LLM.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "âœ”ï¸ Super Short Version (one-liner) : \n",
    "\n",
    "Cold email generator = Structured Job Posting data + Extract Relevant Portfolio links from ChromaDB + Generate\n",
    "                        Cold Email using LLM + prompt..\n",
    "\n",
    "\n",
    "Cold email generator = Structured Job data  + Portfolio links from ChromaDB + LLM with prompt\n",
    "                        ie from structured Job posting data , we will extract relevant Portfolio links from ChromaDB & then using \n",
    "                        LLM with prompt , we will write an cold email..\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e1131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f962e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fb05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdfed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81840a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca360525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec63df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bbcfd0c",
   "metadata": {},
   "source": [
    "# 1 ) Data Collection : Scraping Job Description Data with LangChain\n",
    "\n",
    "    Goal: Show how to extract job posting data and get raw text..\n",
    "          We will use WebBaseLoader() from langchain_community to extract data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c92c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfa026",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imagine Nike has this job portal website \n",
    "\n",
    "### so very first I have to scrap this data from this website ( we have to perform web scraping)\n",
    "### In langchain , we have WebBaseloader() class to perform web scraping which accepts input as URL & return output as data\n",
    "### ie , it will take job portal website as input & extract dta from that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### search as : langcahin webbase code \n",
    "\n",
    "### components - > document loaders - > Web -> WebBaseLoader !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c2a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3f716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://careers.nike.com/ ->> Go to Careers ->> Select Job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5010ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Use any active Nike job posting URL (tell students it may change)\n",
    "loader = WebBaseLoader(\"https://careers.nike.com/data-engineer-i-itc/job/R-75324\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213c984b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"https://careers.nike.com/store-manager-head-coach-nike-groningen/job/R-72549\"\\n\\n\\nthis is a job posting URL & it may change\\nSo please go to NIKe career page & use active job posting link..\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\"https://careers.nike.com/data-engineer-i-itc/job/R-75324\"\n",
    "\n",
    "\n",
    "this is a job posting URL & it may change\n",
    "So please go to NIKe career page & use active job posting link..\n",
    "\n",
    "ie https://careers.nike.com/ ->> Go to Careers ->> Select Job \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b05aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data = loader.load().pop().page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45756a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data Engineer I, ITC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main content\n",
      "Open Virtual Assistant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home\n",
      "\n",
      "\n",
      "Career Areas\n",
      "\n",
      "\n",
      "Total Rewards\n",
      "\n",
      "\n",
      "Life@Nike\n",
      "\n",
      "\n",
      "Purpose\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Language\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Select a Language\n",
      "\n",
      "  Deutsch  \n",
      "  English  \n",
      "  EspaÃ±ol (EspaÃ±a)  \n",
      "  EspaÃ±ol (AmÃ©rica Latina)  \n",
      "  FranÃ§ais  \n",
      "  Italiano  \n",
      "  Nederlands  \n",
      "  Polski  \n",
      "  Tiáº¿ng Viá»‡t  \n",
      "  TÃ¼rkÃ§e  \n",
      "  ç®€ä½“ä¸­æ–‡  \n",
      "  ç¹é«”ä¸­æ–‡  \n",
      "  ×¢Ö´×‘×¨Ö´×™×ª  \n",
      "  í•œêµ­ì–´  \n",
      "  æ—¥æœ¬èª  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Close Menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                Home\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Career Areas\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Total Rewards\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Life@Nike\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Purpose\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jordan Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Converse Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Language\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menu\n",
      "\n",
      "\n",
      "\n",
      "Return to Previous Menu\n",
      "\n",
      "\n",
      "\n",
      "Select a Language\n",
      "\n",
      "  Deutsch  \n",
      "  English  \n",
      "  EspaÃ±ol (EspaÃ±a)  \n",
      "  EspaÃ±ol (AmÃ©rica Latina)  \n",
      "  FranÃ§ais  \n",
      "  Italiano  \n",
      "  Nederlands  \n",
      "  Polski  \n",
      "  Tiáº¿ng Viá»‡t  \n",
      "  TÃ¼rkÃ§e  \n",
      "  ç®€ä½“ä¸­æ–‡  \n",
      "  ç¹é«”ä¸­æ–‡  \n",
      "  ×¢Ö´×‘×¨Ö´×™×ª  \n",
      "  í•œêµ­ì–´  \n",
      "  æ—¥æœ¬èª  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Back to Search\n",
      "\n",
      "                    \n",
      "\n",
      "Data Engineer I, ITC\n",
      "\n",
      "\n",
      "Categories ID\n",
      "\n",
      "\n",
      "\n",
      "Categories URL\n",
      "\n",
      "\n",
      "\n",
      "Position Type\n",
      "Full Time\n",
      "\n",
      "\n",
      "Date Posted\n",
      "\n",
      "\n",
      "\n",
      "Primary Quest ID\n",
      "\n",
      "\n",
      "\n",
      "Second Quest ID\n",
      "\n",
      "\n",
      "\n",
      "Job Classification\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Career area\n",
      "Data\n",
      "\n",
      "\n",
      "Location\n",
      "4/F, WeWork, Embassy GolfLinks, Karnataka, Karnataka 560093, India\n",
      "\n",
      "\n",
      "\n",
      "Job ID\n",
      "R-75324\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            Apply Now\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job Posting\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Facebook\n",
      "Opens In A New Tab\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn\n",
      "Link Opens In New Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Email\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Close-Medium (Default Size)-icon\n",
      "\n",
      "Close Menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Become a Part of the NIKE, Inc. Team\n",
      "NIKE, Inc. does more than outfit the worldâ€™s best athletes. It is a place to explore\n",
      "                            potential, obliterate boundaries\n",
      "                            and push out the edges of what can be. The company looks for people who can grow, think,\n",
      "                            dream and create. Its\n",
      "                            culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers,\n",
      "                            leaders and\n",
      "                            visionaries. At NIKE, Inc. itâ€™s about each person bringing skills and passion to a\n",
      "                            challenging and constantly\n",
      "                            evolving game.\n",
      "\n",
      "WHO YOUâ€™LL WORK WITHYou will be a part of the larger Global Technology organization working on Nikeâ€™s internal product tools and report to the teamâ€™s Engineering Director.Â  You will work day-to-day with a team of engineers, the teamâ€™s Technical Product Manager and Principal Engineers in the organization on software projects to achieve Nikeâ€™s business objectives.Â  You will also engage with other Global Technology functions and teams on organizational and technical goals.WHO WE ARE LOOKING FORWeâ€™re looking for a Data Engineer to solve complex software engineering problems supporting Nikeâ€™s pursuit of delivering state of the art tools to our Consumer Product and Innovation (CP&I) community. The candidate needs to be highly collaborative with peers, productive in a fast-paced development environment and have depth of native cloud software engineering experience.WHAT YOUâ€™LL WORK ONYou will be part of and leading a team of engineers building out tooling for our Consumer Product & Innovation team members. We are investing in building modular, configurable and â€œAPI-Firstâ€ capabilities which will be consumed by modern web applications build with the most recent SPA frameworks. You are expected to help coordinate with other teams and provide guidance and coaching for more junior team members.Bachelor's degree in Computer Science, Engineering, DataÂ Science, or related field; orÂ equivalent combination of education1-2+ years of hands-on experience inÂ data engineering, software development, or related technical rolesFoundational proficiency inÂ SQLÂ for data querying and manipulation, with basic workingÂ knowledge ofÂ PythonÂ for data processing, scripting, and automation tasksExposure toÂ SparkÂ orÂ similar distributed dataÂ processing frameworks, with understandingÂ of bigÂ data conceptsÂ and parallelÂ computingÂ principlesFamiliarity with atÂ least one majorÂ cloud platformÂ (AWS, Azure, Databricks, or Snowflake) and understandingÂ of cloud-based data storageÂ and processing servicesBasic understanding ofÂ data modeling, ETL/ELT processes, and dataÂ pipeline fundamentals, with awarenessÂ of data streamingÂ technologies and real-time data processing conceptsKnowledge ofÂ version control systemsÂ (Git), CI/CD concepts, and DevOps practices related to data engineering workflowsÂ and automated deployment pipelinesExposureÂ toÂ RESTÂ APIÂ developmentÂ and data service integration, with understandingÂ of microservices architecture concepts and basicÂ architecturalÂ designÂ patternsAwarenessÂ ofÂ data visualization conceptsÂ and dashboard design principles; experienceÂ with frameworksÂ suchÂ as React, Vue.js, orÂ Angular is aÂ plusStrongÂ problem-solving skills, collaborativeÂ mindset, and ability to work effectivelyÂ in highly collaborativeÂ environments withÂ demonstrated learningÂ agility and attentionÂ to detail\n",
      "\n",
      "NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a\n",
      "                            generous total rewards\n",
      "                            package, casual work environment, a diverse and inclusive culture, and an electric\n",
      "                            atmosphere for professional\n",
      "                            development. No matter the location, or the role, every Nike employee shares one galvanizing\n",
      "                            mission: To bring\n",
      "                            inspiration and innovation to every athlete* in the world.\n",
      "NIKE, Inc. is an equal opportunity employer. Qualified applicants will receive\n",
      "                            consideration without\n",
      "                            regard to race, color, religion, sex, national origin, age, sexual orientation, gender\n",
      "                            identity, gender expression,\n",
      "                            veteran status, or disability.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                Apply Now\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job Posting\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Faceboox\n",
      "Opens In A New Tab\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn\n",
      "Link Opens In New Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Email\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Close-Medium (Default Size)-icon\n",
      "\n",
      "Close Menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What You Can Expect\n",
      "OUR HIRING GAME PLAN\n",
      "\n",
      "\n",
      "01 Apply\n",
      "Our teams are made up of diverse skillsets, knowledge bases, inputs, ideas and backgrounds.\n",
      "                            We want you to find your fit â€“ review job descriptions, departments and teams to discover\n",
      "                            the role for you.\n",
      "\n",
      "\n",
      "02 Meet a Recruiter or Take an Assessment\n",
      "If selected for a corporate role, a recruiter will reach out to start your interview process\n",
      "                            and be your main contact\n",
      "                            throughout the process. For retail roles, youâ€™ll complete an interactive assessment that\n",
      "                            includes a chat and quizzes and\n",
      "                            takes about 10-20 minutes to complete.Â  No matter the role, we want to learn about you â€“ the\n",
      "                            whole you â€“ so donâ€™t shy\n",
      "                            away from how you approach world-class service and what makes you unique.\n",
      "\n",
      "\n",
      "03 Interview\n",
      "Go into this stage confident by doing your research, understanding what we are looking for\n",
      "                            and being prepared for\n",
      "                            questions that are set up to learn more about you, and your background.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home\n",
      "\n",
      "\n",
      "About Us\n",
      "\n",
      "\n",
      "Contact\n",
      "\n",
      "\n",
      "Talent Community\n",
      "\n",
      "\n",
      "Terms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              \n",
      "                   \n",
      "                    Nike Applicant Privacy Policy\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We offer a number of accommodations to complete our interview process including screen readers, sign language interpreters,\n",
      "                accessible and single location for in-person interviews, closed captioning, and other reasonable modifications as\n",
      "                needed.\n",
      "\n",
      "\n",
      "If you discover, as you navigate our application process, that you need assistance or an accommodation due to a\n",
      "                disability, please contact us at +1 503-671-4156 and include your full name, best way to reach you, and the\n",
      "                accommodation you request to assist with the application process.\n",
      "For more information, please refer to Equal Employment\n",
      "                        Opportunity is The Law.\n",
      "\n",
      "\n",
      "\n",
      "Â©  Nike, Inc. All Rights Reserved\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chat\n",
      "Chat with our AI Assistant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c138330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbf5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### it will go to the HTML structure(website) & extract all the information..\n",
    "### I will have some un-necessary stuffs as well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791f639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ec176",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "U will see , the raw text is messy (as u have headers, menu, footer etc.) !\n",
    "But at the end , u need is structured data so that u can send that data to LLM to generate Cold Emails !\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a00a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Why we want structured data or structured JSON ?\n",
    "\n",
    "\n",
    "When we scrape a job posting from a website, the data is messy, unorganized text..\n",
    "\n",
    "This raw text is difficult for both humans and machines to work with.\n",
    "So we transform it into structured JSON :\n",
    "\n",
    "\n",
    "\n",
    "{\n",
    "  \"role\": \"Data Engineer\",\n",
    "  \"experience\": \"4 yrs\",\n",
    "  \"skills\": [\"Python\", \"Communication\", \"SQL skills\"],\n",
    "  \"description\": \"Collaborative, good with SQL...\"\n",
    "}\n",
    "\n",
    "\n",
    "Will learn in next tutorial , how to get structured data from this raw data by using LLMs + simple prompt ..\n",
    "\n",
    "ie Raw data + (LLMs+Prompting) => Structured data \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71418e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220b29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605bfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab83b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "216c0fb2",
   "metadata": {},
   "source": [
    "# 2) Initialize Llama 3.3 with Groq (LLM Setup)\n",
    "     Goal: Install libraries, connect to Groq, test Llama 3.3.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LLaMA stands for â€œLarge Language Model Meta AI.â€\n",
    "Itâ€™s a family of open-source large language models (LLMs) created by Meta (the company behind Facebook, Instagram, and WhatsApp).\n",
    "\n",
    "\n",
    "There are two main ways to use Metaâ€™s LLaMA models[LLaMA 1 , LLaMA 2 , LLaMA 3  , LLaMA 3.1-----]:\n",
    "\n",
    "\n",
    "1ï¸âƒ£ Run Locally\n",
    "\n",
    "You can download LLaMA and run it on your PC using tools like :\n",
    "\n",
    "Ollama â†’ simple and beginner-friendly setup\n",
    "Hugging Face Transformers â†’ allows advanced customization\n",
    "\n",
    "âš ï¸ Drawback:\n",
    "Large models (e.g., LLaMA 70B) need high-end GPUs, lots of VRAM, and big storage, making local use slow and resource-intensive.\n",
    "\n",
    "\n",
    "\n",
    "2ï¸âƒ£ Run on Cloud (Recommended)\n",
    "\n",
    "Platforms like Groq host LLaMA models in the cloud.\n",
    "Groq uses LPUs (Language Processing Units) â€” hardware built for fast, cheap LLM inference.\n",
    "\n",
    "\n",
    "\n",
    "How to use it:\n",
    "\n",
    "Go to console.groq.com\n",
    "Sign up with Google/email\n",
    "\n",
    "on UI : \n",
    "U will be on the playground , just enter some que & u will see output & they have lot of Models..\n",
    "We are going to use llama-3.3-70b-versatile for our project & for that u need API key \n",
    "\n",
    "Go to API keys :\n",
    "Click on create API key\n",
    "Copy that key ( think of like its a password[dont share with others] )\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163b081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Go to console.groq.com , either login using email or using Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Components -> Chat models -> featured providers -> ChatGroq ( click on this )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0aabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==1.1.0 langchain-core==1.1.0 langchain-community==0.4.1 langchain-groq==1.1.0 langgraph==1.0.3 groq==0.37.0 chromadb==1.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e05c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c896b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:13:34) [MSC v.1944 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make sure langchain is installed !\n",
    "# ! pip install langchain-groq\n",
    "\n",
    "## Successfully installed distro-1.9.0 groq-0.37.0 langchain-groq-1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774b0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq ## takes 10-15 sec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "ChatGroq is a class inside langchain..\n",
    "Lang chain is a framework which makes building llm application easier..\n",
    "\n",
    "\n",
    "first install langchain using pip install \n",
    "then install lanchain groq using pip install \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a7177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## takes 5-10 sec \n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\", ## u can use some other models as well.. (just copy model from console.groq.com/playground)\n",
    "    temperature = 0,\n",
    "    groq_api_key = api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b1ecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virat Kohli is a renowned Indian international cricketer who has been one of the most dominant batsmen in the world for over a decade. Here are some key facts about him:\n",
      "\n",
      "**Early Life and Career**\n",
      "\n",
      "Virat Kohli was born on November 5, 1988, in Delhi, India. He developed a passion for cricket at a young age and began playing at the West Delhi Cricket Academy. Kohli's talent and dedication earned him a spot in the Delhi Under-15 team, and he eventually made his first-class debut for Delhi in 2006.\n",
      "\n",
      "**International Career**\n",
      "\n",
      "Kohli made his international debut for India in 2008, playing in a One-Day International (ODI) against Sri Lanka. He quickly established himself as a key player in the Indian team, known for his aggressive batting style and exceptional fielding skills.\n",
      "\n",
      "**Achievements and Records**\n",
      "\n",
      "Some of Virat Kohli's notable achievements and records include:\n",
      "\n",
      "1. **Fastest to 10,000 ODI runs**: Kohli achieved this milestone in just 205 innings, surpassing Sachin Tendulkar's record.\n",
      "2. **Most centuries in ODIs**: Kohli has scored 46 ODI centuries, the most by any Indian batsman.\n",
      "3. **Highest average in T20Is**: Kohli has an average of 52.73 in T20 Internationals, the highest among all batsmen with a minimum of 1,000 runs.\n",
      "4. **Most runs in a calendar year**: Kohli scored 2,818 runs in 2016, the most by any batsman in a calendar year.\n",
      "5. **ICC Cricketer of the Year**: Kohli has won the ICC Cricketer of the Year award twice, in 2017 and 2018.\n",
      "\n",
      "**Captaincy and Leadership**\n",
      "\n",
      "Kohli was appointed as the captain of the Indian Test team in 2014 and the ODI and T20I teams in 2017. Under his leadership, India has achieved significant success, including:\n",
      "\n",
      "1. **Test series wins**: India won Test series in Australia, England, and South Africa under Kohli's captaincy.\n",
      "2. **ODI series wins**: India won ODI series in Australia, New Zealand, and South Africa under Kohli's captaincy.\n",
      "3. **T20I series wins**: India won T20I series in Australia, New Zealand, and South Africa under Kohli's captaincy.\n",
      "\n",
      "**Personal Life**\n",
      "\n",
      "Kohli is married to actress Anushka Sharma, and the couple has a daughter, Vamika. He is known for his fitness and wellness regime, and has been involved in various philanthropic activities, including supporting children's education and healthcare initiatives.\n",
      "\n",
      "**Awards and Recognition**\n",
      "\n",
      "Kohli has received numerous awards and recognition for his contributions to cricket, including:\n",
      "\n",
      "1. **Padma Shri**: Kohli was awarded the Padma Shri, India's fourth-highest civilian honor, in 2017.\n",
      "2. **Arjuna Award**: Kohli was awarded the Arjuna Award, India's second-highest sporting honor, in 2013.\n",
      "3. **ICC Hall of Fame**: Kohli was inducted into the ICC Hall of Fame in 2021.\n",
      "\n",
      "Overall, Virat Kohli is widely regarded as one of the greatest batsmen in the history of cricket, known for his exceptional skills, dedication, and leadership.\n"
     ]
    }
   ],
   "source": [
    "## Once LLM is setup , lets test Llama 3.3 by asking some query..\n",
    "\n",
    "response = llm.invoke(\"About Virat Kohli\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "It is super fast\n",
    "It went to Groq cloud & asks this que to model \"llama-3.3-70b-versatile\"\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478517bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e07dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71913bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ade0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59a1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba941e30",
   "metadata": {},
   "source": [
    "# 3 ) Basics of Prompt Engineering (Concept Only)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee828a",
   "metadata": {},
   "source": [
    "    In order to get structured data from raw data , u have to use LLM + prompt\n",
    "    So lets understand , what prompts are ?\n",
    "    \n",
    "    Prompts are instructions/commands that guides the LLM to generate the output you want..\n",
    "    Go to ChatGPT => explain raw data in 1 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87f35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879db06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "â­ What is Prompt Engineering ?\n",
    "\n",
    "\n",
    "Prompts are instructions/commands that guides the LLM to generate the output you want..\n",
    "Engineering â†’ Designing those instructions smartly\n",
    "\n",
    "\n",
    "\n",
    "Prompt Engineering = The art of Writing clear, specific prompts so the AI gives better and accurate answers..\n",
    "Instead of giving a simple instruction like:\n",
    "\n",
    "âŒ â€œRecommend a book.â€\n",
    "\n",
    "You give a clear, specific instruction :\n",
    "âœ… â€œRecommend an AI book for beginners.â€\n",
    "\n",
    "Becauseâ€¦\n",
    "\n",
    "â¤ The more specific your prompt,\n",
    "â¤ the better and more accurate the will be GenAI response.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f80b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Based on research , there are 4 imp critical components of Prompt Engineering : \n",
    "\n",
    "1ï¸âƒ£ Context (Role) : Tells the AI who it should act like.\n",
    "â€œYou are an expert GenAI teacher.â€\n",
    "\n",
    "2ï¸âƒ£ Instruction : Tells the AI what task to perform.\n",
    "â€œExplain GenAI in simple words.â€\n",
    "\n",
    "3ï¸âƒ£ Input Data : Gives the AI the information it needs.\n",
    "â€œI am learning GenAI on Udemy and I donâ€™t understand â€˜what is GenAI.â€\n",
    "\n",
    "4ï¸âƒ£ Output Indicator : Tells the AI how the answer should be formatted\n",
    "â€œGive the answer in 2â€“3 lines.â€\n",
    "\n",
    "\n",
    "\n",
    "â€œYou are my study tutor.\n",
    "Please explain the topic in very simple words.\n",
    "I am learning Machine Learning on Udemy and Iâ€™m confused about â€˜Overfittingâ€™.\n",
    "Give the explanation in 2â€“3 lines.â€\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbc999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Types of Prompting :\n",
    "\n",
    "â­ Zero Shot Prompting :\n",
    "\n",
    " means the AI can answer correctly without being shown any example first.\n",
    "â€œTranslate â€˜Good Morningâ€™ to French.â€\n",
    "Output: â€œBonjour.â€\n",
    "\n",
    "â€œTranslate â€˜Good Morningâ€™ to French.â€ => GenAI Model => Output (Bonjour)\n",
    "\n",
    "(No example of translation was given â†’ still works.)\n",
    "\n",
    "\n",
    "\n",
    "â­ Few-Shot Prompting :\n",
    "Few-shot prompting means you give the AI a few examples of what you want before asking the real question.\n",
    "\n",
    "You show the model:\n",
    "\n",
    "an input\n",
    "the correct output\n",
    "repeat this 1â€“3 times\n",
    "\n",
    "Then ask the model to continue the pattern..\n",
    "\n",
    "\n",
    "\n",
    "Example\n",
    "\n",
    "Prompt:\n",
    "Example 1:\n",
    "â€œTranslate â€˜Good Nightâ€™ to French.â€\n",
    "Answer: â€œBonne nuitâ€\n",
    "\n",
    "Example 2:\n",
    "â€œTranslate â€˜Good Eveningâ€™ to French.â€\n",
    "Answer: â€œBonsoirâ€\n",
    "\n",
    "Now Your Turn:\n",
    "â€œTranslate â€˜Good Morningâ€™ to French.â€\n",
    "Answer:\n",
    "\n",
    "AI Output:\n",
    "â€œBonjour.â€\n",
    "\n",
    "â¡ï¸ You gave a few example translations, and the model learned the pattern.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "â­ Ultra-Simple Explanation\n",
    "\n",
    "â¡ï¸ Zero-shot = No examples.\n",
    "â¡ï¸ Few-shot = You show 1â€“3 examples first, then ask the real question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Will tell u in next tutorial why we are learning Types of promting !\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2603e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8ebfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8341546",
   "metadata": {},
   "source": [
    "    In Order to get structured data , we will use below prompt :\n",
    "    {\n",
    "    'role': 'Data Engineer I, ITC',\n",
    "     'experience': '1-2+ years',\n",
    "     'skills': ['SQL', 'Python', 'Spark', 'Cloud platforms (AWS, Azure, Databricks, or Snowflake)'\n",
    "     }\n",
    "     \n",
    "    âœ… What you wrote is Zero-Shot Prompting\n",
    "\n",
    "    Because:\n",
    "\n",
    "    You gave only instructions\n",
    "    You did not provide any examples\n",
    "    You told the model what to extract\n",
    "    And the model figured it out itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca98afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE :\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON in key:value (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "using placeholders {} , \n",
    "    u can send/inject real data into the prompt\n",
    "    ie , Think of {} as variables\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b34ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d98b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc542e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013780b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36663f2b",
   "metadata": {},
   "source": [
    "# 4 ) Using Llama 3.3 to Clean & Structure Job Data (JSON) \n",
    "      Goal: Take raw page_data â†’ Convert it into structured JSON using LLM + PromptTemplate + JsonOutputParser..\n",
    "      \n",
    "      ie Raw data + (LLMs+Prompting) => Structured data \n",
    "      ie on top of Raw data , we will apply LLMs+Prompting to have structured Data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23f32950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nFrom this web scraped data , I need data in the form of JSON ( json with \"role\" , \"experience\" \"skills\", \"description\" )\\nBut why to convert it into JSON ?\\n\\n1st way : using chatgpt tools (simpler, direct)\\n2nd way : using LangChain with an LLM chain (fully automated pipeline) ( ie by giving prompt + LLM )\\n\\n\\nChatGPT is simple and great for one-time manual extraction, but itâ€™s not automated or scalable.\\n\\nLangChain + LLaMA (via Groq) help you to build a fully automated pipeline â€” you can process multiple web pages, \\n            get structured JSON outputs\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "From this web scraped data , I need data in the form of JSON ( json with \"role\" , \"experience\" \"skills\", \"description\" )\n",
    "\n",
    "But why to convert it into JSON ?\n",
    "Bcz Raw scraped data is unstructured and hard to analyze whereas JSON is organized data , \n",
    "    with keys like like role, experience, skills, and description..\n",
    "We can easily perform searching, filtering on json data..\n",
    "\n",
    "\n",
    "Then We can fed/send this JSON into the LLM â€” like querying ChromaDB for portfolio links or generating cold emails.\n",
    "\n",
    "â€œ In short , AI models and analytics pipelines work best with structured data, not raw text.â€\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ways to convert raw data into json data :\n",
    "\n",
    "1st way : using chatgpt tools (simpler, direct)\n",
    "2nd way : using LangChain with an LLM chain (fully automated pipeline) ( ie by giving prompt + LLM )\n",
    "\n",
    "\n",
    "ChatGPT is simple and great for one-time manual extraction, but itâ€™s not automated or scalable.\n",
    "\n",
    "LangChain + LLaMA (via Groq) help you to build a fully automated pipeline â€” you can process multiple web pages, \n",
    "            get structured JSON outputs\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e120e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ef6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Let me first do this in chatgpt :\n",
    "I will copy this portion : \"What u will bring portion \"\n",
    "\n",
    "\n",
    "WHAT WILL YOU BRING\n",
    "\n",
    "Portfolio showcasing expertise in Styling across Retail, Digital, and Campaign.\n",
    "Proven ability to collaborate and adapt to changing creative and business needs.\n",
    "Strong communication skills and ability to work cross-functionally.\n",
    "Bachelorâ€™s degree in Fashion, Marketing, Visual Merchandising, Design, or related field. Will accept any suitable combination of education, experience and training.\n",
    "Deep understanding of fashion, sport, and youth cultureâ€”past and present.\n",
    "Proficiency in Keynote, Excel, and Photoshop. Mac experience preferred.Ability to travel 4â€“6 times per year.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "return it in JSON format with the fields: \"role\" , \"experience\" \"skills\", \"description\" \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "chatgpt output :\n",
    "\n",
    "\n",
    "{\n",
    "  \"role\": \"Stylist / Fashion Visual Merchandiser\",\n",
    "  \"experience\": \"Portfolio showcasing expertise in Styling across Retail, Digital, and Campaign. Proven ability to collaborate and adapt to changing creative and business needs.\",\n",
    "  \"skills\": [\n",
    "    \"Styling (Retail, Digital, Campaign)\",\n",
    "    \"Collaboration and adaptability\",\n",
    "    \"Cross-functional communication\",\n",
    "    \"Fashion, sport, and youth culture expertise\",\n",
    "    \"Keynote\",\n",
    "    \"Excel\",\n",
    "    \"Photoshop\",\n",
    "    \"Mac proficiency\"\n",
    "  ],\n",
    "  \"description\": \"Bachelorâ€™s degree in Fashion, Marketing, Visual Merchandising, Design, or a related field (or an equivalent combination of education, experience, and training). Requires a deep understanding of fashion, sport, and youth cultureâ€”both past and present. Strong communication and collaboration skills, with the ability to work effectively across teams. Must be able to travel 4â€“6 times per year.\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad317bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd way : using LangChain with an LLM chain (fully automated pipeline) ( ie by giving prompt + LLM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9b1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Your LLaMA model takes messy text and converts it into a clean JSON format..\n",
    "\n",
    "Steps:\n",
    "\n",
    "1ï¸âƒ£ Define the LLM â€“ we will use Groqâ€™s LLaMA model using your API key.\n",
    "2ï¸âƒ£ Define the Prompt Template â€“ Create a dynamic prompt that instructs the LLM model (e.g., extract job info into JSON).\n",
    "3ï¸âƒ£ Create the Chain â€“ Link the Prompt Template and LLM using the pipe (|) operator.\n",
    "4ï¸âƒ£ Run the Chain â€“ Pass the input data (e.g., scraped website text).\n",
    "5ï¸âƒ£ Print or review Output â€“ Get the final structured response (JSON format).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LangChain automates the workflow â†’\n",
    "Input (raw text) â†’ Prompt â†’ LLaMA model (via Groq) â†’ Output (structured JSON)\n",
    "\n",
    "\n",
    "\n",
    "In data cleaning, our goal is to convert unstructured text into clean, structured data..\n",
    "\n",
    "Input (raw scraped text)\n",
    "        â†“\n",
    "Prompt (instruction to extract key fields)\n",
    "        â†“\n",
    "LLaMA Model via Groq (processes and structures the data)\n",
    "        â†“\n",
    "Output (clean, structured JSON)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f2a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce18c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select Navigation(Base packages) -->> Core-->> prompts -->> PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc729b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb9b11fd",
   "metadata": {},
   "source": [
    "## 4(a) Define the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b22611ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",   # or any other model from console.groq.com/playground\n",
    "    temperature=0,\n",
    "    groq_api_key=\"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\"   # ğŸ‘ˆ use your valid API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8dd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed3959ed",
   "metadata": {},
   "source": [
    "## 4(b) Define the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6340966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## We have to give instruction to the LLM (using PromptTemplate)\n",
    "## now we will write a prompt for our LLM & for this we will import this PromptTemplate class !\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE :\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON in key:value (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21a7998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.prompt.PromptTemplate"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08fa2716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_groq.chat_models.ChatGroq"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58104a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09c375a",
   "metadata": {},
   "source": [
    "## 4(c) Create chain using the `|`(pipe) operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44870ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_extract | llm\n",
    "\n",
    "## prompt_extract | llm ( ie we are getting a prompt & passing it to LLM)\n",
    "## ie So chain knows : â€œTake the input â†’ define the prompt â†’ send it to the LLM â†’ return the result..â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdccb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62a40e9a",
   "metadata": {},
   "source": [
    "## 4(d) Run it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff7b756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninvoke({...}) â†’ method used to run the chain\\n\\n\"page_data\" â†’ name of the placeholder used in your prompt template\\npage_data â†’ the actual variable containing your scraped text\\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"page_data\": page_data})\n",
    "\n",
    "\n",
    "'''\n",
    "invoke({...}) â†’ method used to run the chain\n",
    "\n",
    "\"page_data\" â†’ name of the placeholder used in your prompt template\n",
    "page_data â†’ the actual variable containing your scraped text\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f086c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79ce4139",
   "metadata": {},
   "source": [
    "## 4(e) Print output :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38d09d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"role\": \"Data Engineer I, ITC\",\n",
      "  \"experience\": \"1-2+ years\",\n",
      "  \"skills\": [\n",
      "    \"SQL\",\n",
      "    \"Python\",\n",
      "    \"Spark\",\n",
      "    \"Cloud platforms (AWS, Azure, Databricks, or Snowflake)\",\n",
      "    \"Data modeling\",\n",
      "    \"ETL/ELT processes\",\n",
      "    \"Data pipeline fundamentals\",\n",
      "    \"Data streaming technologies\",\n",
      "    \"Real-time data processing concepts\",\n",
      "    \"Version control systems (Git)\",\n",
      "    \"CI/CD concepts\",\n",
      "    \"DevOps practices\",\n",
      "    \"REST API development\",\n",
      "    \"Microservices architecture concepts\",\n",
      "    \"Data visualization concepts\"\n",
      "  ],\n",
      "  \"description\": \"Weâ€™re looking for a Data Engineer to solve complex software engineering problems supporting Nikeâ€™s pursuit of delivering state of the art tools to our Consumer Product and Innovation (CP&I) community. The candidate needs to be highly collaborative with peers, productive in a fast-paced development environment and have depth of native cloud software engineering experience.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n",
    "\n",
    "## looks like JSON but still a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a24bca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99ca34fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nabove text is in str format & we need to convert it into json & for which we can use jsonparser \\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "above text is in str format & we need to convert it into json & for which we can use jsonparser \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d4ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb6cc52",
   "metadata": {},
   "source": [
    "## 4(f) Parse JSON string into simple JSON or Python dict !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cdd2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2570afde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Data Engineer I, ITC',\n",
       " 'experience': '1-2+ years',\n",
       " 'skills': ['SQL',\n",
       "  'Python',\n",
       "  'Spark',\n",
       "  'Cloud platforms (AWS, Azure, Databricks, or Snowflake)',\n",
       "  'Data modeling',\n",
       "  'ETL/ELT processes',\n",
       "  'Data pipeline fundamentals',\n",
       "  'Data streaming technologies',\n",
       "  'Real-time data processing concepts',\n",
       "  'Version control systems (Git)',\n",
       "  'CI/CD concepts',\n",
       "  'DevOps practices',\n",
       "  'REST API development',\n",
       "  'Microservices architecture concepts',\n",
       "  'Data visualization concepts'],\n",
       " 'description': 'Weâ€™re looking for a Data Engineer to solve complex software engineering problems supporting Nikeâ€™s pursuit of delivering state of the art tools to our Consumer Product and Innovation (CP&I) community. The candidate needs to be highly collaborative with peers, productive in a fast-paced development environment and have depth of native cloud software engineering experience.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_parser = JsonOutputParser()\n",
    "json_response = json_parser.parse(response.content)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d2490e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61876a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2b719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746a1d8b",
   "metadata": {},
   "source": [
    "# 5 ) What is a Vector Database ?\n",
    "    Why we are not using Simple or Traditional Dbs or SQL ?\n",
    "    What is a Vector DB ?\n",
    "    Why Vector DB is used here ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q ? Why we are not using simple dbs or traditional DB ?\n",
    "Ans : Bcz SQL databases can only match exact text , they do not understand meaning/semantics..\n",
    "\n",
    "Example :\n",
    "SQL matches exact words, not related words\n",
    "\n",
    "    SQL can only answer:\n",
    "    \"Find rows where text equals 'Python'\"\n",
    "\n",
    "    It cannot answer:\n",
    "    \"Find technologies similar to Python\"\n",
    "    \n",
    "    Bcz it does not understand meaning / context..\n",
    "    \n",
    "    \n",
    "Give me technologies related to Python..\n",
    "\n",
    "SQL output:\n",
    "Python\n",
    "\n",
    "ğŸ¤– Vector DB output:\n",
    "Pandas\n",
    "Django\n",
    "TensorFlow\n",
    "Machine Learning\n",
    "\n",
    "\n",
    "Because Vector DB understands semantic similarity, not just text equality.\n",
    "\n",
    "SQL = exact match\n",
    "Vector DB = similarity match\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q -> What is a Vector DB ?\n",
    "Ans : A Vector Database is a special type of database that stores data in the form of vectors (numbers) \n",
    "      so that it can understand meaning and find similar items, not just exact matches...\n",
    "\n",
    "    ğŸ§¾ Why is it called â€œVectorâ€ database ?\n",
    "        Because each item (text, image, etc.) is converted into a vector â€”\n",
    "        & these vectors let the database to measure similarity..\n",
    "        example :\n",
    "        \"Python\" will be stored as some vector  , let say â†’ [0.12, 0.91, 0.44, 0.77]\n",
    "        \"Java\"   will be stored as some vector  , let say  â†’ [0.15, 0.88, 0.42, 0.80]\n",
    "        \n",
    "        \n",
    "        \n",
    "        embedding is the process of converting text, images, or data into vectors\n",
    "        ie on \"Python\" , we will apply \"Embedding\" => we will get [0.12, 0.91, 0.44, 0.77]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q : Why Vector DB ?\n",
    "Ans : In this project , we want to extract relevant portfolio links for the Job description or skills , thats why \n",
    "      we need that database or we have to store data into VectorDB , so that later-on , we can do similarity search \n",
    "      between :\n",
    "            the skills in the job posting\n",
    "            and\n",
    "            the technologies in our portfolio projects\n",
    "        \n",
    "    Core Flow in 1 line :\n",
    "    Skills in Job Posting â†’ Similarity search in VectorDB â†’ Retrieve matching portfolio links\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467c204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de146e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e335d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe56cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a0f0b2f",
   "metadata": {},
   "source": [
    "# 6 ) Building the Portfolio Vector Store with ChromaDB !\n",
    "      Goal: Load portfolio.csv, create ChromaDB PersistentClient, insert data in database, test a query.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11574fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### it's a dictionary !\n",
    "### once this step is over , next step is to prepare chromaDB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "So I have this csv file where cols are :\n",
    "technologies on which TCS/Info works   ,    Portfolio links \n",
    "\n",
    "-> Portfolio links : okay these are the projects of companies that we have done in this particular tech !\n",
    "  ( By the way , these are dummy urls , just for sake of learning ! )\n",
    "\n",
    "\n",
    "\n",
    "-> So I need to insert this things into chromaDB !\n",
    " whenever there is a job posting  , it should extract all the skills from the job & it will match to one or more of these tech \n",
    " for that company on which he is working & then it should retrieve this portfolio URLs which i will use in my E-Mail !\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266e46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0ad593",
   "metadata": {},
   "source": [
    "## 6(a) Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e3f5193-7b6f-44ab-adc3-7e510064e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\shant\\anaconda3\\envs\\genai_email\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shant\\anaconda3\\envs\\genai_email\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shant\\anaconda3\\envs\\genai_email\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shant\\anaconda3\\envs\\genai_email\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.8/11.3 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.3 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 22.2 MB/s  0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pytz, pandas\n",
      "\n",
      "   ---------------------------------------- 0/2 [pytz]\n",
      "   ---------------------------------------- 0/2 [pytz]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   ---------------------------------------- 2/2 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.3 pytz-2025.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27063c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Techstack</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>React Native, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-native-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frontend, TypeScript, Angular</td>\n",
       "      <td>https://example.com/typescript-frontend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>React, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Time Series Forecasting, Prophet, ARIMA</td>\n",
       "      <td>https://example.com/timeseries-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kotlin, Android, Firebase</td>\n",
       "      <td>https://example.com/kotlin-android-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iOS, Swift, Core Data</td>\n",
       "      <td>https://example.com/ios-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iOS, Swift, ARKit</td>\n",
       "      <td>https://example.com/ios-ar-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Angular,.NET, SQL Server</td>\n",
       "      <td>https://example.com/angular-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science, MLflow, Streamlit</td>\n",
       "      <td>https://example.com/datascience-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Flutter, Firebase, GraphQL</td>\n",
       "      <td>https://example.com/flutter-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n",
       "      <td>https://example.com/vue-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Android TV, Kotlin, Android NDK</td>\n",
       "      <td>https://example.com/android-tv-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Backend, Kotlin, Spring Boot</td>\n",
       "      <td>https://example.com/kotlin-backend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Python, Django, MySQL</td>\n",
       "      <td>https://example.com/python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Java, Spring Boot, Oracle</td>\n",
       "      <td>https://example.com/java-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NLP, Hugging Face Transformers, SpaCy</td>\n",
       "      <td>https://example.com/nlp-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Python, Scikit-learn, Pandas</td>\n",
       "      <td>https://example.com/ml-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLMs, LangChain, Groq, OpenAI API</td>\n",
       "      <td>https://example.com/genai-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TensorFlow, Keras, Deep Learning</td>\n",
       "      <td>https://example.com/deep-learning-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Reinforcement Learning, Gym, Stable Baselines</td>\n",
       "      <td>https://example.com/rl-portfolio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Techstack  \\\n",
       "0                  React Native, Node.js, MongoDB   \n",
       "1                   Frontend, TypeScript, Angular   \n",
       "2                         React, Node.js, MongoDB   \n",
       "3         Time Series Forecasting, Prophet, ARIMA   \n",
       "4                       Kotlin, Android, Firebase   \n",
       "5                           iOS, Swift, Core Data   \n",
       "6                               iOS, Swift, ARKit   \n",
       "7                        Angular,.NET, SQL Server   \n",
       "8                 Data Science, MLflow, Streamlit   \n",
       "9                      Flutter, Firebase, GraphQL   \n",
       "10              Vue.js, Ruby on Rails, PostgreSQL   \n",
       "11                Android TV, Kotlin, Android NDK   \n",
       "12                   Backend, Kotlin, Spring Boot   \n",
       "13                          Python, Django, MySQL   \n",
       "14                      Java, Spring Boot, Oracle   \n",
       "15          NLP, Hugging Face Transformers, SpaCy   \n",
       "16                   Python, Scikit-learn, Pandas   \n",
       "17              LLMs, LangChain, Groq, OpenAI API   \n",
       "18               TensorFlow, Keras, Deep Learning   \n",
       "19  Reinforcement Learning, Gym, Stable Baselines   \n",
       "\n",
       "                                                Links  \n",
       "0          https://example.com/react-native-portfolio  \n",
       "1   https://example.com/typescript-frontend-portfolio  \n",
       "2                 https://example.com/react-portfolio  \n",
       "3            https://example.com/timeseries-portfolio  \n",
       "4        https://example.com/kotlin-android-portfolio  \n",
       "5                   https://example.com/ios-portfolio  \n",
       "6                https://example.com/ios-ar-portfolio  \n",
       "7               https://example.com/angular-portfolio  \n",
       "8           https://example.com/datascience-portfolio  \n",
       "9               https://example.com/flutter-portfolio  \n",
       "10                  https://example.com/vue-portfolio  \n",
       "11           https://example.com/android-tv-portfolio  \n",
       "12       https://example.com/kotlin-backend-portfolio  \n",
       "13               https://example.com/python-portfolio  \n",
       "14                 https://example.com/java-portfolio  \n",
       "15                  https://example.com/nlp-portfolio  \n",
       "16                   https://example.com/ml-portfolio  \n",
       "17                https://example.com/genai-portfolio  \n",
       "18        https://example.com/deep-learning-portfolio  \n",
       "19                   https://example.com/rl-portfolio  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\shant\\_14.. Entire_GenAI_Projects\\Email_generator/portfolio.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c48d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feda28f8",
   "metadata": {},
   "source": [
    "## 6(b) Create ChromaDB collection & insert rows or data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ebb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now I will iterate on this dataframe & insert record one by one dataframe row into chroma-DB !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1661bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb\n",
    "\n",
    "## chromadb-1.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cc10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82d3f131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nCreate a connection to ChromaDB\\n\\n\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Inserting data into ChromaDB :\n",
    "\n",
    "I  ) Create a connection to ChromaDB\n",
    "II ) Create collection ( Its like a table where I can insert my records/data/documents )\n",
    "III) Insert data\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "532754ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "## Create a connection to ChromaDB\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "\n",
    "## Create collection !\n",
    "collection = client.get_or_create_collection(name = \"portfolio\")\n",
    "\n",
    "\n",
    "### Summary : When u use PersistentClient() , it will create a folder & stored record inside folder.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "when you use chromadb.Client() : it will create chromaDb client in memory\n",
    "when you use chromadb.PersistentClient() : it will create chromaDb client in a disk \n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore') : \n",
    "\n",
    "\n",
    "When I execute above code , it will create \"db\" stored in a folder so that next time when I want to retrieve my data , I have \n",
    "it on my disk..\n",
    "U will see a folder vectorstore in my \"C:\\Users\\shant\\_14.. Entire_GenAI_Projects\\Email_generator\"\n",
    "\n",
    "\n",
    "\n",
    "Inside db , I have to define my collection...\n",
    "( It's like in db , I am creating a table where I can insert my records )\n",
    "( Once u have collection , u have to insert data/records & here records are called documents ) !\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572737d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5fc5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not collection.count() : ## If the collection is empty (count == 0) , ie collection has zero documents, then insert data..\n",
    "    ## else we will have duplicate data records !\n",
    "    \n",
    "    for index , row in df.iterrows() :\n",
    "        collection.add(documents = row[\"Techstack\"],\n",
    "                       metadatas = {\"links\": row[\"Links\"]},\n",
    "                       ids = [str(uuid.uuid4())])\n",
    "        \n",
    "### metadata is a link & techstack is your main document.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c990ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "if not collection.count(): ## If the collection has zero documents, then insert data..\n",
    "\n",
    "If the collection already has data (count > 0), then:\n",
    "\n",
    "    Skip insertion\n",
    "    Avoid duplicates\n",
    "    Faster startup\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e49fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a02f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e80871",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If I do query as \" I need a person with experience in Python , experience in React \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f4aafe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/react-portfolio'},\n",
       "  {'links': 'https://example.com/react-native-portfolio'}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = collection.query(query_texts = [\"experience in Python\"  , \"experience in React\"] , n_results = 2).get('metadatas', [])\n",
    "links\n",
    "\n",
    "## n_results : I want 2 results \n",
    "## get('metadatas', []) : I want meta-data (which is portfolio link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For first one \"experience in Python\" , we have \n",
    "  {'links': 'https://example.com/ml-python-portfolio'} ,\n",
    "  {'links': 'https://example.com/python-portfolio'}\n",
    "\n",
    "For second one \"experience in React\" , we have :\n",
    "  {'links': 'https://example.com/react-portfolio'},\n",
    "  {'links': 'https://example.com/react-native-portfolio'}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9197a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec562e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb50db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39e063a6",
   "metadata": {},
   "source": [
    "# 7 ) Generate Cold Email using Llama 3.3 + ChromaDB\n",
    "      Goal : Use the structured JSON job info + portfolio links from ChromaDB + LLM to generate the final email.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb150821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Data Engineer I, ITC',\n",
       " 'experience': '1-2+ years',\n",
       " 'skills': ['SQL',\n",
       "  'Python',\n",
       "  'Spark',\n",
       "  'Cloud platforms (AWS, Azure, Databricks, or Snowflake)',\n",
       "  'Data modeling',\n",
       "  'ETL/ELT processes',\n",
       "  'Data pipeline fundamentals',\n",
       "  'Data streaming technologies',\n",
       "  'Real-time data processing concepts',\n",
       "  'Version control systems (Git)',\n",
       "  'CI/CD concepts',\n",
       "  'DevOps practices',\n",
       "  'REST API development',\n",
       "  'Microservices architecture concepts',\n",
       "  'Data visualization concepts'],\n",
       " 'description': 'Weâ€™re looking for a Data Engineer to solve complex software engineering problems supporting Nikeâ€™s pursuit of delivering state of the art tools to our Consumer Product and Innovation (CP&I) community. The candidate needs to be highly collaborative with peers, productive in a fast-paced development environment and have depth of native cloud software engineering experience.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02dfd4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SQL',\n",
       " 'Python',\n",
       " 'Spark',\n",
       " 'Cloud platforms (AWS, Azure, Databricks, or Snowflake)',\n",
       " 'Data modeling',\n",
       " 'ETL/ELT processes',\n",
       " 'Data pipeline fundamentals',\n",
       " 'Data streaming technologies',\n",
       " 'Real-time data processing concepts',\n",
       " 'Version control systems (Git)',\n",
       " 'CI/CD concepts',\n",
       " 'DevOps practices',\n",
       " 'REST API development',\n",
       " 'Microservices architecture concepts',\n",
       " 'Data visualization concepts']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = json_response\n",
    "job[\"skills\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e8e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c0415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8671006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For all the skills that NIKE needs, we will show matching company portfolio links from our ChromaDB collection.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81dc004f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/magento-portfolio'},\n",
       "  {'links': 'https://example.com/wordpress-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/kotlin-android-portfolio'},\n",
       "  {'links': 'https://example.com/kotlin-backend-portfolio'}],\n",
       " [{'links': 'https://example.com/xamarin-portfolio'},\n",
       "  {'links': 'https://example.com/devops-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/magento-portfolio'}],\n",
       " [{'links': 'https://example.com/kotlin-backend-portfolio'},\n",
       "  {'links': 'https://example.com/devops-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/devops-portfolio'}],\n",
       " [{'links': 'https://example.com/android-tv-portfolio'},\n",
       "  {'links': 'https://example.com/flutter-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/magento-portfolio'}],\n",
       " [{'links': 'https://example.com/devops-portfolio'},\n",
       "  {'links': 'https://example.com/magento-portfolio'}],\n",
       " [{'links': 'https://example.com/magento-portfolio'},\n",
       "  {'links': 'https://example.com/wordpress-portfolio'}],\n",
       " [{'links': 'https://example.com/devops-portfolio'},\n",
       "  {'links': 'https://example.com/full-stack-js-portfolio'}],\n",
       " [{'links': 'https://example.com/vue-portfolio'},\n",
       "  {'links': 'https://example.com/typescript-frontend-portfolio'}],\n",
       " [{'links': 'https://example.com/android-portfolio'},\n",
       "  {'links': 'https://example.com/xamarin-portfolio'}],\n",
       " [{'links': 'https://example.com/magento-portfolio'},\n",
       "  {'links': 'https://example.com/wordpress-portfolio'}]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = collection.query(query_texts = job[\"skills\"], n_results = 2).get('metadatas', [])\n",
    "links\n",
    "\n",
    "## n_results : I want 2 results \n",
    "## get('metadatas', []) : I want metadata (which is portfolio link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c215505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29499357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now lets create one more prompt template for forming/generating an cold email :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5eed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "âœ… Final Version (Infosys Email Context)\n",
    "\n",
    "Steps:\n",
    "\n",
    "1ï¸âƒ£ Define the LLM â€“ Use Groqâ€™s LLaMA model using your API key for generating the email.\n",
    "\n",
    "2ï¸âƒ£ Define the Prompt Template â€“ Create a dynamic prompt that instructs the LLM to act as Mohan (BDE at Infosys) \n",
    "                                and write a cold email using placeholders like {job_description} and {link_list}.\n",
    "                                \n",
    "3ï¸âƒ£ Create the Chain â€“ Link the prompt and LLM model using the pipe (|) operator \n",
    "                        (chain_email = prompt_email_infosys | llm).\n",
    "                        \n",
    "4ï¸âƒ£ Run the Chain â€“ Pass input parameters such as the job description and portfolio links to the chain.\n",
    "\n",
    "5ï¸âƒ£ Print or Review Output â€“ Retrieve the generated cold email from res.content and verify the content \n",
    "                            (ensuring it includes Infosysâ€™s capabilities and links).\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ea3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64aa4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5254c360",
   "metadata": {},
   "source": [
    "## 7..(a) Define the LLM â€“ Use Groqâ€™s LLaMA model using your API key for generating the email.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "569f4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model = \"llama-3.3-70b-versatile\" ,   # or any other model from console.groq.com/playground\n",
    "    temperature = 0 ,\n",
    "    groq_api_key = \"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\"   # ğŸ‘ˆ use your valid API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267843ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4b127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cc1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4387026c",
   "metadata": {},
   "source": [
    "## 7..(b) Define prompt for Infosys cold email : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5747ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Instruction Summary :\n",
    "\n",
    "We have to give instruction to the LLM (using PromptTemplate) :\n",
    "\n",
    "\n",
    "Act as Mohan, BDE at Infosys.\n",
    "\n",
    "Write a cold email for the given job description.\n",
    "\n",
    "Highlight Infosysâ€™s expertise.\n",
    "\n",
    "Include relevant portfolio links.\n",
    "\n",
    "Avoid any preamble â€” start directly with the email.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "** : It emphasize and bold crucial elements like the persona's name (Mohan) and BDE & company (Infosys). \n",
    "This ensures the AI model clearly identifies and adheres to the specified roles and company when generating the email content.\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d23b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_email_infosys = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are **Mohan**, a **Business Development Executive** at **Accenture**. \n",
    "        Accenture is a global digital services and consulting leader that drives client digital transformation using AI and automation for business process optimization.\n",
    "        Over our experience, we have empowered numerous global enterprises with tailored solutions, fostering scalability, \n",
    "        process optimization, cost reduction, and heightened overall efficiency..\n",
    "        \n",
    "        Your job is to write a cold email to the client regarding the job mentioned above describing the capability of **Accenture** in fulfilling their needs.\n",
    "        Also add the most relevant ones from the following links to showcase Infosys's portfolio: {link_list}\n",
    "        Remember you are **Mohan**, BDE at **Accenture**.\n",
    "        Do not provide a preamble.\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8020fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd98f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fed348",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ie we are giving instruction to LLM regarding write a cold email to client regarding job mentioned & add the portfolio link.\n",
    "### {link_list} : when-ever u see something in curly brackets , it means we are giving arguments to our prompt template.. \n",
    "### so this link_list are the particular links that u will give in prompt template..\n",
    "\n",
    "### ie we are giving 2 parameters : job_description & link list..\n",
    "\n",
    "'''\n",
    "\n",
    "âœ… In short:\n",
    "Weâ€™re giving the LLM two dynamic inputs â†’ {job_description} + {link_list} â†’\n",
    "and asking it to produce a tailored cold email based on those.\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac508e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444afd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c550aa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/magento-portfolio'},\n",
       "  {'links': 'https://example.com/wordpress-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/kotlin-android-portfolio'},\n",
       "  {'links': 'https://example.com/kotlin-backend-portfolio'}],\n",
       " [{'links': 'https://example.com/xamarin-portfolio'},\n",
       "  {'links': 'https://example.com/devops-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/magento-portfolio'}],\n",
       " [{'links': 'https://example.com/kotlin-backend-portfolio'},\n",
       "  {'links': 'https://example.com/devops-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/devops-portfolio'}],\n",
       " [{'links': 'https://example.com/android-tv-portfolio'},\n",
       "  {'links': 'https://example.com/flutter-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/magento-portfolio'}],\n",
       " [{'links': 'https://example.com/devops-portfolio'},\n",
       "  {'links': 'https://example.com/magento-portfolio'}],\n",
       " [{'links': 'https://example.com/magento-portfolio'},\n",
       "  {'links': 'https://example.com/wordpress-portfolio'}],\n",
       " [{'links': 'https://example.com/devops-portfolio'},\n",
       "  {'links': 'https://example.com/full-stack-js-portfolio'}],\n",
       " [{'links': 'https://example.com/vue-portfolio'},\n",
       "  {'links': 'https://example.com/typescript-frontend-portfolio'}],\n",
       " [{'links': 'https://example.com/android-portfolio'},\n",
       "  {'links': 'https://example.com/xamarin-portfolio'}],\n",
       " [{'links': 'https://example.com/magento-portfolio'},\n",
       "  {'links': 'https://example.com/wordpress-portfolio'}]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9546e847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Data Engineer I, ITC',\n",
       " 'experience': '1-2+ years',\n",
       " 'skills': ['SQL',\n",
       "  'Python',\n",
       "  'Spark',\n",
       "  'Cloud platforms (AWS, Azure, Databricks, or Snowflake)',\n",
       "  'Data modeling',\n",
       "  'ETL/ELT processes',\n",
       "  'Data pipeline fundamentals',\n",
       "  'Data streaming technologies',\n",
       "  'Real-time data processing concepts',\n",
       "  'Version control systems (Git)',\n",
       "  'CI/CD concepts',\n",
       "  'DevOps practices',\n",
       "  'REST API development',\n",
       "  'Microservices architecture concepts',\n",
       "  'Data visualization concepts'],\n",
       " 'description': 'Weâ€™re looking for a Data Engineer to solve complex software engineering problems supporting Nikeâ€™s pursuit of delivering state of the art tools to our Consumer Product and Innovation (CP&I) community. The candidate needs to be highly collaborative with peers, productive in a fast-paced development environment and have depth of native cloud software engineering experience.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job\n",
    "\n",
    "## json_response ( extracted text in json from job postings.. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b248c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea5a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125055bb",
   "metadata": {},
   "source": [
    "## 7..(c) Create the Chain â€“ Link the prompt and model using the pipe (|) operator to form the workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f84f64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_email = prompt_email_infosys | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d586c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71cd5986",
   "metadata": {},
   "source": [
    "## 7..(d) Run the Chain â€“ Pass input parameters such as the job description and portfolio links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddc6fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain_email.invoke({\"job_description\" : str(job), \"link_list\" : links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "res = chain_email.invoke({\"job_description\" : str(job) , \"link_list\" : links})\n",
    "\n",
    "\n",
    "we will send job_description ( entire json data )\n",
    "& regarding all the skills that NIKE needs, we will show matching company portfolio links on which company have worked \n",
    "    from our ChromaDB collection..\n",
    "\n",
    "\n",
    "In simple terms:\n",
    "ğŸ‘‰ The LLM gets the job details ::  str(job) + relevant portfolio links(links)..\n",
    "ğŸ‘‰ It then writes a cold email (from Mohan, Infosys BDE) explaining how Infosys can fulfill NIKEâ€™s requirements, \n",
    "    including matching project links for each skill..\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a3dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354b067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22b43237",
   "metadata": {},
   "source": [
    "## 7(e).. Print or Review Output !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f9cc4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Expert Data Engineering Solutions for Nike's Consumer Product and Innovation Community\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I came across the job description for a Data Engineer I, ITC at Nike, and I am excited to introduce Accenture's capabilities in fulfilling your requirements. As a global digital services and consulting leader, we drive client digital transformation using AI and automation for business process optimization. Our expertise in cloud software engineering, data modeling, and ETL/ELT processes makes us an ideal partner for delivering state-of-the-art tools to your Consumer Product and Innovation (CP&I) community.\n",
      "\n",
      "Our team has extensive experience in designing and implementing data pipelines, leveraging cloud platforms such as AWS, Azure, Databricks, and Snowflake. We are well-versed in data streaming technologies, real-time data processing concepts, and version control systems like Git. Our expertise in CI/CD concepts, DevOps practices, and microservices architecture concepts ensures seamless integration and deployment of solutions.\n",
      "\n",
      "I would like to highlight some of our relevant portfolio links that demonstrate our capabilities:\n",
      "\n",
      "* https://example.com/ml-python-portfolio (Machine Learning and Python expertise)\n",
      "* https://example.com/devops-portfolio (DevOps and CI/CD capabilities)\n",
      "* https://example.com/kotlin-backend-portfolio (Cloud-based backend development)\n",
      "\n",
      "These examples showcase our ability to deliver scalable, efficient, and optimized solutions that meet the needs of global enterprises like Nike. Our team is committed to collaborative and productive partnerships, ensuring that our solutions align with your business objectives.\n",
      "\n",
      "I would be delighted to discuss how Accenture can support Nike's pursuit of delivering innovative tools to the CP&I community. Please let me know if you would like to schedule a call to explore our capabilities further.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Mohan\n",
      "Business Development Executive\n",
      "Accenture\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8788bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb6864fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQuick evalaution check \\n\\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Quick evalaution check \n",
    "\n",
    "\n",
    "ğŸ§  Summary\n",
    "\n",
    "Evaluation Type\tDescription\tWhen to Use\n",
    "LLM-as-Judge (criteria)\tUses another LLM to score quality and relevance\tFor high-quality evaluation\n",
    "Multi-Criteria Evaluation\tJudges on relevance, tone, completeness\tFor detailed scoring\n",
    "Keyword Check\tFast, offline check\tFor quick validation\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d26d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989369d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec84fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1b735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Now provide proper project structure \n",
    "\n",
    "\n",
    "Open Pycharm/VSCode/Spyder or any python IDE \n",
    "\n",
    "create folder known as \"app\"..\n",
    "\n",
    "In app folder , create main.py\n",
    "resource folder ( files , images , text )\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8d830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1ed92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37295f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea3713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7b609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054d4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
