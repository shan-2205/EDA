{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2810: expected 2 fields, saw 5\\nSkipping line 4641: expected 2 fields, saw 5\\nSkipping line 7171: expected 2 fields, saw 5\\nSkipping line 11220: expected 2 fields, saw 5\\nSkipping line 13809: expected 2 fields, saw 5\\nSkipping line 14132: expected 2 fields, saw 5\\nSkipping line 14293: expected 2 fields, saw 5\\nSkipping line 14865: expected 2 fields, saw 5\\nSkipping line 17419: expected 2 fields, saw 5\\nSkipping line 22801: expected 2 fields, saw 5\\nSkipping line 25001: expected 2 fields, saw 5\\nSkipping line 26603: expected 2 fields, saw 5\\nSkipping line 26742: expected 2 fields, saw 5\\nSkipping line 29702: expected 2 fields, saw 5\\nSkipping line 32767: expected 2 fields, saw 5\\nSkipping line 32878: expected 2 fields, saw 5\\nSkipping line 35643: expected 2 fields, saw 5\\nSkipping line 36550: expected 2 fields, saw 5\\nSkipping line 38732: expected 2 fields, saw 5\\nSkipping line 40567: expected 2 fields, saw 5\\nSkipping line 40576: expected 2 fields, saw 5\\nSkipping line 41864: expected 2 fields, saw 5\\nSkipping line 46861: expected 2 fields, saw 5\\nSkipping line 47939: expected 2 fields, saw 5\\nSkipping line 48628: expected 2 fields, saw 5\\nSkipping line 48908: expected 2 fields, saw 5\\nSkipping line 57582: expected 2 fields, saw 5\\nSkipping line 58782: expected 2 fields, saw 5\\nSkipping line 58984: expected 2 fields, saw 5\\nSkipping line 61518: expected 2 fields, saw 5\\nSkipping line 63451: expected 2 fields, saw 5\\nSkipping line 68141: expected 2 fields, saw 5\\nSkipping line 72083: expected 2 fields, saw 5\\nSkipping line 74027: expected 2 fields, saw 5\\nSkipping line 77811: expected 2 fields, saw 5\\nSkipping line 83958: expected 2 fields, saw 5\\nSkipping line 85295: expected 2 fields, saw 5\\nSkipping line 88665: expected 2 fields, saw 5\\nSkipping line 89198: expected 2 fields, saw 5\\nSkipping line 92499: expected 2 fields, saw 5\\nSkipping line 92751: expected 2 fields, saw 5\\nSkipping line 93689: expected 2 fields, saw 5\\nSkipping line 94776: expected 2 fields, saw 5\\nSkipping line 97334: expected 2 fields, saw 5\\nSkipping line 102316: expected 2 fields, saw 5\\nSkipping line 103421: expected 2 fields, saw 5\\nSkipping line 106872: expected 2 fields, saw 5\\nSkipping line 109363: expected 2 fields, saw 5\\nSkipping line 110117: expected 2 fields, saw 5\\nSkipping line 110465: expected 2 fields, saw 5\\nSkipping line 113843: expected 2 fields, saw 5\\nSkipping line 115634: expected 2 fields, saw 5\\nSkipping line 121518: expected 2 fields, saw 5\\nSkipping line 123692: expected 2 fields, saw 5\\nSkipping line 124708: expected 2 fields, saw 5\\nSkipping line 129608: expected 2 fields, saw 5\\nSkipping line 133176: expected 2 fields, saw 5\\nSkipping line 135532: expected 2 fields, saw 5\\nSkipping line 138042: expected 2 fields, saw 5\\nSkipping line 139485: expected 2 fields, saw 5\\nSkipping line 140401: expected 2 fields, saw 5\\nSkipping line 144093: expected 2 fields, saw 5\\nSkipping line 149850: expected 2 fields, saw 5\\nSkipping line 151831: expected 2 fields, saw 5\\nSkipping line 158014: expected 2 fields, saw 5\\nSkipping line 162047: expected 2 fields, saw 5\\nSkipping line 164515: expected 2 fields, saw 5\\nSkipping line 170313: expected 2 fields, saw 5\\nSkipping line 171325: expected 2 fields, saw 5\\nSkipping line 171424: expected 2 fields, saw 5\\nSkipping line 175920: expected 2 fields, saw 5\\nSkipping line 176210: expected 2 fields, saw 5\\nSkipping line 183603: expected 2 fields, saw 5\\nSkipping line 190264: expected 2 fields, saw 5\\nSkipping line 191683: expected 2 fields, saw 5\\nSkipping line 191988: expected 2 fields, saw 5\\nSkipping line 195450: expected 2 fields, saw 5\\nSkipping line 195754: expected 2 fields, saw 5\\nSkipping line 197124: expected 2 fields, saw 5\\nSkipping line 199263: expected 2 fields, saw 5\\nSkipping line 202603: expected 2 fields, saw 5\\nSkipping line 209960: expected 2 fields, saw 5\\nSkipping line 213218: expected 2 fields, saw 5\\nSkipping line 217060: expected 2 fields, saw 5\\nSkipping line 220121: expected 2 fields, saw 5\\nSkipping line 223518: expected 2 fields, saw 5\\nSkipping line 226293: expected 2 fields, saw 5\\nSkipping line 227035: expected 2 fields, saw 7\\nSkipping line 227341: expected 2 fields, saw 5\\nSkipping line 227808: expected 2 fields, saw 5\\nSkipping line 228516: expected 2 fields, saw 5\\nSkipping line 228733: expected 2 fields, saw 5\\nSkipping line 232043: expected 2 fields, saw 5\\nSkipping line 232426: expected 2 fields, saw 5\\nSkipping line 234490: expected 2 fields, saw 5\\nSkipping line 239626: expected 2 fields, saw 5\\nSkipping line 240461: expected 2 fields, saw 5\\nSkipping line 244518: expected 2 fields, saw 5\\nSkipping line 245395: expected 2 fields, saw 5\\nSkipping line 246168: expected 2 fields, saw 5\\nSkipping line 246655: expected 2 fields, saw 5\\nSkipping line 246752: expected 2 fields, saw 5\\nSkipping line 247189: expected 2 fields, saw 5\\nSkipping line 250276: expected 2 fields, saw 5\\nSkipping line 255327: expected 2 fields, saw 5\\nSkipping line 257094: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 264626: expected 2 fields, saw 5\\nSkipping line 265028: expected 2 fields, saw 5\\nSkipping line 269150: expected 2 fields, saw 5\\nSkipping line 271360: expected 2 fields, saw 5\\nSkipping line 273975: expected 2 fields, saw 5\\nSkipping line 274742: expected 2 fields, saw 5\\nSkipping line 276227: expected 2 fields, saw 5\\nSkipping line 279807: expected 2 fields, saw 5\\nSkipping line 283425: expected 2 fields, saw 5\\nSkipping line 287468: expected 2 fields, saw 5\\nSkipping line 292995: expected 2 fields, saw 5\\nSkipping line 293496: expected 2 fields, saw 5\\nSkipping line 293735: expected 2 fields, saw 5\\nSkipping line 295060: expected 2 fields, saw 5\\nSkipping line 296643: expected 2 fields, saw 5\\nSkipping line 296848: expected 2 fields, saw 5\\nSkipping line 308926: expected 2 fields, saw 5\\nSkipping line 310360: expected 2 fields, saw 5\\nSkipping line 317004: expected 2 fields, saw 5\\nSkipping line 318207: expected 2 fields, saw 5\\nSkipping line 331783: expected 2 fields, saw 5\\nSkipping line 333864: expected 2 fields, saw 5\\nSkipping line 335958: expected 2 fields, saw 5\\nSkipping line 336290: expected 2 fields, saw 5\\nSkipping line 343526: expected 2 fields, saw 5\\nSkipping line 343857: expected 2 fields, saw 5\\nSkipping line 344059: expected 2 fields, saw 5\\nSkipping line 348691: expected 2 fields, saw 5\\nSkipping line 353446: expected 2 fields, saw 5\\nSkipping line 357073: expected 2 fields, saw 5\\nSkipping line 359753: expected 2 fields, saw 5\\nSkipping line 359974: expected 2 fields, saw 5\\nSkipping line 366534: expected 2 fields, saw 5\\nSkipping line 369514: expected 2 fields, saw 5\\nSkipping line 377759: expected 2 fields, saw 5\\nSkipping line 379327: expected 2 fields, saw 5\\nSkipping line 380769: expected 2 fields, saw 5\\nSkipping line 381073: expected 2 fields, saw 5\\nSkipping line 381489: expected 2 fields, saw 5\\nSkipping line 386304: expected 2 fields, saw 5\\nSkipping line 387635: expected 2 fields, saw 5\\nSkipping line 389613: expected 2 fields, saw 5\\nSkipping line 392604: expected 2 fields, saw 5\\nSkipping line 393184: expected 2 fields, saw 5\\nSkipping line 395530: expected 2 fields, saw 5\\nSkipping line 396939: expected 2 fields, saw 5\\nSkipping line 397385: expected 2 fields, saw 5\\nSkipping line 397509: expected 2 fields, saw 5\\nSkipping line 402902: expected 2 fields, saw 5\\nSkipping line 405187: expected 2 fields, saw 5\\nSkipping line 408412: expected 2 fields, saw 5\\nSkipping line 419423: expected 2 fields, saw 5\\nSkipping line 420962: expected 2 fields, saw 5\\nSkipping line 425965: expected 2 fields, saw 5\\nSkipping line 427496: expected 2 fields, saw 5\\nSkipping line 438881: expected 2 fields, saw 5\\nSkipping line 439776: expected 2 fields, saw 5\\nSkipping line 440345: expected 2 fields, saw 5\\nSkipping line 445507: expected 2 fields, saw 5\\nSkipping line 445548: expected 2 fields, saw 5\\nSkipping line 447184: expected 2 fields, saw 5\\nSkipping line 448603: expected 2 fields, saw 5\\nSkipping line 451732: expected 2 fields, saw 5\\nSkipping line 458249: expected 2 fields, saw 5\\nSkipping line 460274: expected 2 fields, saw 5\\nSkipping line 467630: expected 2 fields, saw 5\\nSkipping line 473961: expected 2 fields, saw 5\\nSkipping line 476281: expected 2 fields, saw 5\\nSkipping line 478010: expected 2 fields, saw 5\\nSkipping line 478322: expected 2 fields, saw 5\\nSkipping line 479999: expected 2 fields, saw 5\\nSkipping line 480898: expected 2 fields, saw 5\\nSkipping line 481688: expected 2 fields, saw 5\\nSkipping line 485193: expected 2 fields, saw 5\\nSkipping line 485519: expected 2 fields, saw 5\\nSkipping line 486000: expected 2 fields, saw 5\\nSkipping line 489063: expected 2 fields, saw 5\\nSkipping line 494525: expected 2 fields, saw 5\\nSkipping line 495009: expected 2 fields, saw 5\\nSkipping line 501954: expected 2 fields, saw 5\\nSkipping line 508035: expected 2 fields, saw 5\\nSkipping line 508828: expected 2 fields, saw 5\\nSkipping line 509833: expected 2 fields, saw 5\\nSkipping line 510410: expected 2 fields, saw 5\\nSkipping line 518229: expected 2 fields, saw 5\\nSkipping line 520302: expected 2 fields, saw 5\\nSkipping line 520340: expected 2 fields, saw 5\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 525174: expected 2 fields, saw 5\\nSkipping line 526251: expected 2 fields, saw 5\\nSkipping line 529611: expected 2 fields, saw 5\\nSkipping line 531398: expected 2 fields, saw 5\\nSkipping line 534146: expected 2 fields, saw 5\\nSkipping line 544954: expected 2 fields, saw 5\\nSkipping line 553002: expected 2 fields, saw 5\\nSkipping line 553883: expected 2 fields, saw 5\\nSkipping line 553887: expected 2 fields, saw 5\\nSkipping line 553915: expected 2 fields, saw 5\\nSkipping line 554172: expected 2 fields, saw 5\\nSkipping line 563534: expected 2 fields, saw 5\\nSkipping line 565191: expected 2 fields, saw 5\\nSkipping line 574108: expected 2 fields, saw 5\\nSkipping line 574412: expected 2 fields, saw 5\\nSkipping line 575985: expected 2 fields, saw 5\\nSkipping line 580091: expected 2 fields, saw 5\\nSkipping line 582682: expected 2 fields, saw 5\\nSkipping line 585885: expected 2 fields, saw 5\\nSkipping line 590171: expected 2 fields, saw 5\\nSkipping line 591924: expected 2 fields, saw 5\\nSkipping line 592515: expected 2 fields, saw 5\\nSkipping line 593888: expected 2 fields, saw 5\\nSkipping line 596245: expected 2 fields, saw 5\\nSkipping line 607344: expected 2 fields, saw 5\\nSkipping line 607633: expected 2 fields, saw 5\\nSkipping line 610939: expected 2 fields, saw 5\\nSkipping line 613638: expected 2 fields, saw 5\\nSkipping line 615643: expected 2 fields, saw 5\\nSkipping line 615901: expected 2 fields, saw 5\\nSkipping line 617389: expected 2 fields, saw 5\\nSkipping line 634641: expected 2 fields, saw 5\\nSkipping line 635755: expected 2 fields, saw 5\\nSkipping line 646243: expected 2 fields, saw 5\\nSkipping line 647165: expected 2 fields, saw 5\\nSkipping line 648610: expected 2 fields, saw 5\\nSkipping line 648772: expected 2 fields, saw 5\\nSkipping line 651833: expected 2 fields, saw 5\\nSkipping line 653663: expected 2 fields, saw 5\\nSkipping line 656233: expected 2 fields, saw 5\\nSkipping line 656694: expected 2 fields, saw 5\\nSkipping line 659783: expected 2 fields, saw 5\\nSkipping line 660478: expected 2 fields, saw 5\\nSkipping line 661133: expected 2 fields, saw 5\\nSkipping line 661736: expected 2 fields, saw 5\\nSkipping line 669827: expected 2 fields, saw 5\\n'\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('F:/Data Science projects/By_krish/Machine-LEarning-PAssword--master/Machine-LEarning-PAssword--master/data.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      password  strength\n",
       "0     kzde5577         1\n",
       "1     kino3434         1\n",
       "2    visi7k1yr         1\n",
       "3     megzy123         1\n",
       "4  lamborghin1         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    1\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       password  strength\n",
       "367579      NaN         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['password'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords_tuple=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kzde5577', 1],\n",
       "       ['kino3434', 1],\n",
       "       ['visi7k1yr', 1],\n",
       "       ...,\n",
       "       ['184520socram', 1],\n",
       "       ['marken22a', 1],\n",
       "       ['fxx4pw4g', 1]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passwords_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(passwords_tuple) #shuffling randomly for robustness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[labels[1] for labels in passwords_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[labels[0] for labels in passwords_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x6e6022cc08>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='strength',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kzde5577',\n",
       " 'kino3434',\n",
       " 'visi7k1yr',\n",
       " 'megzy123',\n",
       " 'megzy123',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'megzy123',\n",
       " 'kzde5577',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'megzy123',\n",
       " 'kzde5577',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'visi7k1yr',\n",
       " 'lamborghin1',\n",
       " 'as326159',\n",
       " 'megzy123',\n",
       " 'asv5o9yu',\n",
       " 'kino3434',\n",
       " '6975038lp',\n",
       " 'visi7k1yr',\n",
       " 'idofo673',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'kzde5577',\n",
       " 'intel1',\n",
       " 'as326159',\n",
       " 'universe2908',\n",
       " 'universe2908',\n",
       " 'kzde5577',\n",
       " 'jerusalem393',\n",
       " 'kzde5577',\n",
       " 'jerusalem393',\n",
       " 'czuodhj972',\n",
       " 'klara-tershina3H',\n",
       " 'lamborghin1',\n",
       " 'faranumar91',\n",
       " 'visi7k1yr',\n",
       " '6975038lp',\n",
       " 'g067057895',\n",
       " 'v1118714',\n",
       " 'schalke04',\n",
       " 'trabajonet9',\n",
       " 'pHyqueDIyNQ8vmhb',\n",
       " 'yitbos77',\n",
       " 'v1118714',\n",
       " 'jerusalem393',\n",
       " '6975038lp',\n",
       " 'schalke04',\n",
       " 'g067057895',\n",
       " 'idofo673',\n",
       " 'asv5o9yu',\n",
       " 'gaymaids1',\n",
       " 'go7kew7a2po',\n",
       " 'visi7k1yr',\n",
       " 'sbl571017',\n",
       " 'lamborghin1',\n",
       " 'v1118714',\n",
       " 'kzde5577',\n",
       " 'juliel009',\n",
       " 'ok>bdk',\n",
       " 'exitos2009',\n",
       " 'calcifer32',\n",
       " 'sbl571017',\n",
       " '612035180tok',\n",
       " 'juliel009',\n",
       " 'go7kew7a2po',\n",
       " 'patri1973',\n",
       " 'alimagik1',\n",
       " 'czuodhj972',\n",
       " 'lsdlsd1',\n",
       " 'TyWM72UNEex8Q8Y',\n",
       " 'yk530mg8',\n",
       " 'kjkjkj1',\n",
       " 'ok>bdk',\n",
       " 'idofo673',\n",
       " 'hodygid757',\n",
       " 'juliana19',\n",
       " 'lsdlsd1',\n",
       " 'lamborghin1',\n",
       " 'hpqkoxsn5',\n",
       " 'p2share',\n",
       " 'yqugu927',\n",
       " 'czuodhj972',\n",
       " '612035180tok',\n",
       " 'gill02',\n",
       " 'alimagik1',\n",
       " 'hayhayq2',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'Iamthelegend1!',\n",
       " 'exitos2009',\n",
       " 'visi7k1yr',\n",
       " 'lsdlsd1',\n",
       " 'cigicigi123',\n",
       " 'fk9qi21m',\n",
       " '2021848709.',\n",
       " 'snolyuj04',\n",
       " 'megzy123',\n",
       " 'openup12',\n",
       " '2021848709.',\n",
       " 'j09000',\n",
       " '52558000aaa',\n",
       " 'il0vey0u',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'jerusalem393',\n",
       " 'go7kew7a2po',\n",
       " 'exitos2009',\n",
       " 'kswa2mrv',\n",
       " 'rntprns7',\n",
       " 'khmer100.03278&?><Mnb',\n",
       " 'kjkjkj1',\n",
       " 'jytifok873',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'k1k2k3k4k5k6',\n",
       " 'asv5o9yu',\n",
       " 'hodygid757',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'cigicigi123',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'gkrqjs6',\n",
       " 'woon12',\n",
       " 'ass359',\n",
       " 'klara-tershina3H',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'exitos2009',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'kjkjkj1',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'hayhayq2',\n",
       " 'megzy123',\n",
       " 'patri1973',\n",
       " 'megzy123',\n",
       " 'ejeko677',\n",
       " 'rogyh820',\n",
       " 'fnmsdha476',\n",
       " 'farrukhcse12',\n",
       " 'woon12',\n",
       " 'rntprns7',\n",
       " 'as326159',\n",
       " 'khmer100.03278&?><Mnb',\n",
       " 'klara-tershina3H',\n",
       " 'p2share',\n",
       " 'intel1',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'c3h8bkzr',\n",
       " 'intel1',\n",
       " 'elonex24',\n",
       " 'g067057895',\n",
       " 'oekojWyH120063',\n",
       " 'gill02',\n",
       " 'lsdlsd1',\n",
       " 'il0vey0u',\n",
       " 'yu4cmn',\n",
       " '3y6iwef2g6',\n",
       " 'z3ro1sm',\n",
       " 'cigicigi123',\n",
       " '2akira2',\n",
       " 'icap12',\n",
       " 'yk530mg8',\n",
       " 'k1k2k3k4k5k6',\n",
       " 's9830950044',\n",
       " '52558000aaa',\n",
       " 'v1118714',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'khmer100.03278&?><Mnb',\n",
       " 'potatobus150',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'denise18',\n",
       " '123net123',\n",
       " 'yitbos77',\n",
       " 'memjan123',\n",
       " 'yu4cmn',\n",
       " 'xiau5ff',\n",
       " 'sbl571017',\n",
       " '2akira2',\n",
       " 'calcifer32',\n",
       " '0169395484a',\n",
       " 'yuri110995',\n",
       " 'pato221182',\n",
       " 'pato221182',\n",
       " 'g067057895',\n",
       " 'alimagik1',\n",
       " 'qn5xpg3k00',\n",
       " 'klara-tershina3H',\n",
       " 'khmer100.03278&?><Mnb',\n",
       " 'g3rappa',\n",
       " 'j09000',\n",
       " 'afs34214',\n",
       " 'jerusalem393',\n",
       " 'icap12',\n",
       " 'prisonbreak1',\n",
       " 'yqugu927',\n",
       " 'xyws951753',\n",
       " '0169395484a',\n",
       " 'juliana19',\n",
       " 'teste10',\n",
       " 'yllime123',\n",
       " 'yqugu927',\n",
       " 'mmm23mm',\n",
       " 'kzde5577',\n",
       " 'v1118714',\n",
       " 'kayal123',\n",
       " '4osxw4r',\n",
       " 'teemteem97',\n",
       " '123maxbala',\n",
       " 'pato221182',\n",
       " 'openup12',\n",
       " 'snolyuj04',\n",
       " 'poseidon2011',\n",
       " 'sarahi1628',\n",
       " 'v10rica',\n",
       " '5gzj5uf',\n",
       " 'moken7',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'intel1',\n",
       " 's0xwym7h',\n",
       " 'snolyuj04',\n",
       " 'g3rappa',\n",
       " 'znbl5tj1',\n",
       " 'kikeq102',\n",
       " 'trabajonet9',\n",
       " 'ginger972',\n",
       " 'jalingo1',\n",
       " '4fqa52vecr',\n",
       " '1972vishara',\n",
       " 'trabajonet9',\n",
       " 'TyWM72UNEex8Q8Y',\n",
       " 'robot425',\n",
       " '215466kenyi',\n",
       " '2010server',\n",
       " 'wibi182d',\n",
       " 'ldteugao6',\n",
       " 'fk9qi21m',\n",
       " 'atigi839',\n",
       " 'yllime123',\n",
       " 'omakiva153',\n",
       " 'robot425',\n",
       " 'hayhayq2',\n",
       " 'kjkjkj1',\n",
       " 'g3rappa',\n",
       " 'olmaz.',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'lamborghin1',\n",
       " '929865yt',\n",
       " 'xW8-3w7-MFB-CKH',\n",
       " 'yut0838828185',\n",
       " '52558000aaa',\n",
       " 'sbl571017',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'k1k2k3k4k5k6',\n",
       " 'ginger972',\n",
       " 'jalingo1',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'olmaz.',\n",
       " 'virush1n1',\n",
       " '10Erjrlmebup0n',\n",
       " 'matiofox08',\n",
       " 'djngeyut2707',\n",
       " '3y6iwef2g6',\n",
       " 'ikanez886',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'p2share',\n",
       " 'oekojWyH120063',\n",
       " '123net123',\n",
       " '2010server',\n",
       " 'lamborghin1',\n",
       " 'omakiva153',\n",
       " 'nello11',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'gaymaids1',\n",
       " 'bozoxik602',\n",
       " '5gzj5uf',\n",
       " '2yz4ewwg',\n",
       " 'kzde5577',\n",
       " 'robot425',\n",
       " 'alimagik1',\n",
       " 'zoobike04',\n",
       " '215466kenyi',\n",
       " 'gozv3e5',\n",
       " 'lzhzad1989',\n",
       " 'woon12',\n",
       " '5gzj5uf',\n",
       " 'x8512514',\n",
       " 'il0vey0u',\n",
       " 'poseidon2011',\n",
       " 'robot425',\n",
       " 'holamundo1',\n",
       " 'znbl5tj1',\n",
       " 'potatobus150',\n",
       " 'xlxlxl777',\n",
       " 'schalke04',\n",
       " 'mohantra1',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'UF1Z2WjE5Mg26R1K',\n",
       " 'kikeq102',\n",
       " '0870330135a',\n",
       " 'wisal1234',\n",
       " 'alchimie79',\n",
       " 'visi7k1yr',\n",
       " 'z7zbgIDkzMQeHUd9',\n",
       " 'franczuk33',\n",
       " 'nicolas05',\n",
       " 'jalingo1',\n",
       " 'lamborghin1',\n",
       " 'juany57',\n",
       " 'vuqADUSatAJO800',\n",
       " 'kry1z9',\n",
       " 'c3h8bkzr',\n",
       " 'UF1Z2WjE5Mg26R1K',\n",
       " 'exitos2009',\n",
       " 'p2share',\n",
       " 'z7zbgIDkzMQeHUd9',\n",
       " 'alchimie79',\n",
       " 'colorado27',\n",
       " 'gkrqjs6',\n",
       " 'gkrqjs6',\n",
       " 'nK0yKXTU0NQHZE2e',\n",
       " 'ikanez886',\n",
       " 'omakiva153',\n",
       " 'gaymaids1',\n",
       " '4fqa52vecr',\n",
       " 'tin030201',\n",
       " 'clave08',\n",
       " 'p@sslng2diword',\n",
       " 't8IkFRDIxMAFV2JW',\n",
       " '12345yolanda',\n",
       " 'y0unus',\n",
       " 'hosna1368',\n",
       " 'alchimie79',\n",
       " 'asv5o9yu',\n",
       " 'a110804032',\n",
       " 'v1118714',\n",
       " 'ejeko677',\n",
       " 'z7zbgIDkzMQeHUd9',\n",
       " 'balamuc123',\n",
       " 'ejeko677',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'ekufite742',\n",
       " 'tomas7896',\n",
       " 'lzhzad1989',\n",
       " 'c3h8bkzr',\n",
       " 'change201',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " 'barboza221294',\n",
       " 'w9209640',\n",
       " 'den019520',\n",
       " 'yqugu927',\n",
       " 'nokia6020',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'mario489800',\n",
       " 'bugatti01',\n",
       " '1qa2ws3ed4rf',\n",
       " 'sknq7m0',\n",
       " 'gdfn76',\n",
       " 'exitos2009',\n",
       " 'iwaguh884',\n",
       " '2fakjv',\n",
       " 'gvczfel801',\n",
       " '3CgRg8DA1NQY1iEj',\n",
       " 'X9WVojjE4MgVAIiR',\n",
       " 'zgmfnwuq25',\n",
       " 'yu86640132',\n",
       " 'ikanez886',\n",
       " 's4m2dx9e6',\n",
       " 'oatcake87',\n",
       " 'omakiva153',\n",
       " 'ekufite742',\n",
       " 'juliel009',\n",
       " 'abizar08',\n",
       " 'polo2014',\n",
       " 'Iamthelegend1!',\n",
       " 'il0vey0u',\n",
       " 'kyxvufl37',\n",
       " 'obstacle25',\n",
       " 'uxyloga692',\n",
       " 'teemteem97',\n",
       " 'gerardway1',\n",
       " 'a2531106',\n",
       " 'XqMB7vDMzOQocAFV',\n",
       " 'ycqtgdso3',\n",
       " 'farrukhcse12',\n",
       " 'z888888',\n",
       " '2yz4ewwg',\n",
       " 'cigicigi123',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " '283671gus',\n",
       " 'gandhi8513',\n",
       " 'denise18',\n",
       " 'pHyqueDIyNQ8vmhb',\n",
       " 'gtlek',\n",
       " 'kry1z9',\n",
       " 'IjUcOtYqAwel725',\n",
       " 'servbot88',\n",
       " '5gzj5uf',\n",
       " '2akira2',\n",
       " '07dpv1127b',\n",
       " 'rogyh820',\n",
       " 'kenneth610',\n",
       " 'tucagu356',\n",
       " 'bellsuki1',\n",
       " 'xanyrum650',\n",
       " 'clave08',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'barboza221294',\n",
       " 'jbtcnd6',\n",
       " 'khurram_',\n",
       " 'u03kz6ez',\n",
       " 'lsdlsd1',\n",
       " 'd4xQ3LjUwMQFVCYQ',\n",
       " 'jalingo1',\n",
       " 'jerusalem393',\n",
       " 'patty94',\n",
       " 'gerardway1',\n",
       " '3vszncp4',\n",
       " 'kuntz80',\n",
       " 'graciela2',\n",
       " 'klara-tershina3H',\n",
       " 'kitty555',\n",
       " 'franczuk33',\n",
       " 'y0unus',\n",
       " 'go7kew7a2po',\n",
       " 'tucagu356',\n",
       " 'olmaz.',\n",
       " 'ryjypes139',\n",
       " 'cUFUSYKIPuGo024',\n",
       " 'marita1',\n",
       " '10Erjrlmebup0n',\n",
       " '64whbrb351',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'alchimie79',\n",
       " '612035180tok',\n",
       " 'tamanagung6',\n",
       " '4fqa52vecr',\n",
       " 'saule123',\n",
       " 'jr88072635',\n",
       " '1234159hero',\n",
       " 'xiau5ff',\n",
       " '1597535youssi',\n",
       " 'autan88',\n",
       " '4165000yakub',\n",
       " 'franczuk33',\n",
       " '159951josh',\n",
       " 'memjan123',\n",
       " 'yy4129',\n",
       " 'meriton23',\n",
       " 'ixehawojEPe418',\n",
       " 'gkrqjs6',\n",
       " 'X9WVojjE4MgVAIiR',\n",
       " 'virush1n1',\n",
       " 'alchimie79',\n",
       " 'jalingo1',\n",
       " 'cigicigi123',\n",
       " 'juany57',\n",
       " 'xtswdypgh936',\n",
       " 'pazzini24',\n",
       " '123nicole',\n",
       " 'taurofive16',\n",
       " 'tim80327',\n",
       " 'czuodhj972',\n",
       " 'meriton23',\n",
       " 'www32223222',\n",
       " '0169395484a',\n",
       " 'sbaUsoTA1OAzuevI',\n",
       " 'sknq7m0',\n",
       " 'isqizkg1',\n",
       " 'khurram_',\n",
       " 'tia150979',\n",
       " 'klara-tershina3H',\n",
       " 'saule123',\n",
       " 'examy624',\n",
       " 'aosmaxd0',\n",
       " 'tamanagung6',\n",
       " '3vszncp4',\n",
       " 'wibi182d',\n",
       " 'sknq7m0',\n",
       " 'junaid5',\n",
       " 'cristiano7',\n",
       " '631ihOZogELoVap',\n",
       " 'kabrito1',\n",
       " 'laedbchsx687',\n",
       " 'www32223222',\n",
       " 'v1118714',\n",
       " 'butisugo39',\n",
       " '4TXr5KDYxNQVTo4g',\n",
       " 'VMjz4eTkxNAbOyUU',\n",
       " '1991vikash',\n",
       " '1qa2ws3ed4rf',\n",
       " 'Scipio21152030067254',\n",
       " '4TXr5KDYxNQVTo4g',\n",
       " 'qopybuxi2',\n",
       " 'jUV4dSDQwNwPpA36',\n",
       " 'poilkjmnb987',\n",
       " 'ginger972',\n",
       " 'gvczfel801',\n",
       " 'folashade1',\n",
       " 'sanki1',\n",
       " 'oscar2002',\n",
       " '4TXr5KDYxNQVTo4g',\n",
       " '64959rodro',\n",
       " 'kry1z9',\n",
       " 'tucagu356',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'kikeq102',\n",
       " 'ppnyadam09',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'qn5xpg3k00',\n",
       " 'portales1',\n",
       " '847XagYxUHUXOW',\n",
       " 'ram@!sita15392',\n",
       " 'ryjypes139',\n",
       " 'xp;ysmybst',\n",
       " '4osxw4r',\n",
       " '4TXr5KDYxNQVTo4g',\n",
       " '64whbrb351',\n",
       " 'princ3sa',\n",
       " 'buqodym199',\n",
       " '33kanun03',\n",
       " 'ginger972',\n",
       " 'password0880',\n",
       " 'kry1z9',\n",
       " 'znbl5tj1',\n",
       " 'alimagik1',\n",
       " 'deryxi704',\n",
       " 'mickael12',\n",
       " 'warriors08',\n",
       " 'diarie1',\n",
       " 'franczuk33',\n",
       " 'aquhih220',\n",
       " 'as8594505',\n",
       " 'x8512514',\n",
       " '0169395484a',\n",
       " 'jonothepoop1',\n",
       " 'mazdarx7',\n",
       " 'memjan123',\n",
       " 'sasuke4',\n",
       " 'YADHJIGSAWS11',\n",
       " 'asv5o9yu',\n",
       " 'roxana1993',\n",
       " 'cesarmaio1',\n",
       " '2652033abc',\n",
       " 'olmaz.',\n",
       " 'kry1z9',\n",
       " 'urban1',\n",
       " 'taurofive16',\n",
       " 'TyWM72UNEex8Q8Y',\n",
       " 'intel1',\n",
       " '746xitEGiqObog',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'Herzberg@ABBOTT33656888commerce',\n",
       " 'www32223222',\n",
       " '3vszncp4',\n",
       " 'x8512514',\n",
       " 'juliel009',\n",
       " 'ok>bdk',\n",
       " 'kikeq102',\n",
       " 'www32223222',\n",
       " '7mV0pKTA3MgHy8Jv',\n",
       " 'obstacle25',\n",
       " 'zoobike04',\n",
       " '2GnTStTE4Mw4MTwv',\n",
       " 'ram@!sita15392',\n",
       " '838188linh',\n",
       " 'gozv3e5',\n",
       " 'folashade1',\n",
       " 'u6c8vhow',\n",
       " 'memjan123',\n",
       " 'overlord3127',\n",
       " '07dpv1127b',\n",
       " 'yut0838828185',\n",
       " 'sanjaime1',\n",
       " 'synyxyr723',\n",
       " 'IjUcOtYqAwel725',\n",
       " '283671gus',\n",
       " 'ebogel225',\n",
       " 'kP82iqDMxNgBMxBP',\n",
       " 'upomel180',\n",
       " 'atigi839',\n",
       " 'g3rappa',\n",
       " 'qopybuxi2',\n",
       " 'oscar69',\n",
       " 'ekufite742',\n",
       " 'uou2dae',\n",
       " 'kdl9cl53',\n",
       " 'arigato3',\n",
       " 'y0unus',\n",
       " 'ikanez886',\n",
       " 'djngeyut2707',\n",
       " 'cerner09',\n",
       " 'nokia6020',\n",
       " 'ykfums1',\n",
       " 'seng987321',\n",
       " 'juliel009',\n",
       " 'yogesh143',\n",
       " 'yami12',\n",
       " 'hasan18',\n",
       " 'bc5e4vca',\n",
       " 'jalingo1',\n",
       " 'PEPITO00',\n",
       " 'virush1n1',\n",
       " 't8IkFRDIxMAFV2JW',\n",
       " 'okn9zp9o',\n",
       " 'wibi182d',\n",
       " 'asdasdf1',\n",
       " 'studenko123',\n",
       " 'bozoxik602',\n",
       " 'grazi0201',\n",
       " 'uou2dae',\n",
       " 'woaini0',\n",
       " 'polo2014',\n",
       " 'yjuqseb416',\n",
       " 'qwekl12',\n",
       " 'calcifer32',\n",
       " 'h1h2h3h4h5',\n",
       " 'yy4129',\n",
       " 'kdl9cl53',\n",
       " '238wofutUtIGyf',\n",
       " 'Ju6BIMTU0MwYXtL4',\n",
       " 's9830950044',\n",
       " 'servbot88',\n",
       " 'butisugo39',\n",
       " 'jr88072635',\n",
       " 'tim80327',\n",
       " 'as8594505',\n",
       " 'mario489800',\n",
       " 'parent777',\n",
       " '6yy6yy',\n",
       " 'twil8x0',\n",
       " 'xiau5ff',\n",
       " '1597535youssi',\n",
       " 'muoaqxwc21',\n",
       " 'laedbchsx687',\n",
       " 'ajyrew547',\n",
       " 'plumilla1',\n",
       " 'aio42fv',\n",
       " 'pardalgg5',\n",
       " 'exitos2009',\n",
       " 'bjolgvhs69',\n",
       " 'okn9zp9o',\n",
       " 'princ3sa',\n",
       " 'asv5o9yu',\n",
       " 'sergius1964',\n",
       " 'han19660120',\n",
       " 'Truelove19902610',\n",
       " 'muoaqxwc21',\n",
       " 'kyxvufl37',\n",
       " 'u03kz6ez',\n",
       " '52756652a',\n",
       " 'aqyba894',\n",
       " 'nokia6020',\n",
       " 'xzeyfbi495',\n",
       " '248sUqiFEJuRag',\n",
       " '4lgYVfzk1MwuzHcn',\n",
       " '147963asd',\n",
       " '147963asd',\n",
       " 'yjuqseb416',\n",
       " '26522876p',\n",
       " 'yami12',\n",
       " 'go7kew7a2po',\n",
       " 'ypodahe201',\n",
       " 'znbl5tj1',\n",
       " 'pacific52',\n",
       " 'z888888',\n",
       " 'icap12',\n",
       " 'nhfdff2512',\n",
       " 'ok>bdk',\n",
       " 'ypodahe201',\n",
       " 'wisal1234',\n",
       " 'hodygid757',\n",
       " 'finisterra1',\n",
       " 'wbtdrieus345',\n",
       " 'hisnipes1',\n",
       " 'clumsy0619',\n",
       " '23deagosto',\n",
       " 'natalia12',\n",
       " 'xzeyfbi495',\n",
       " 'yuri110995',\n",
       " '159951josh',\n",
       " '2GnTStTE4Mw4MTwv',\n",
       " 'pxjwmeqyn5',\n",
       " 'hotdog20',\n",
       " 'Jovan13lovekenthjusvan4ever',\n",
       " 'parent777',\n",
       " 'han19660120',\n",
       " 'ikanez886',\n",
       " 'as8594505',\n",
       " 'lsdlsd1',\n",
       " 'oatcake87',\n",
       " 'servbot88',\n",
       " 'khurram_',\n",
       " 'akucinta12',\n",
       " 'walterivl13',\n",
       " 'GGmm26120904..',\n",
       " 'a110804032',\n",
       " 'mickael12',\n",
       " 'bc5e4vca',\n",
       " 'ilunia20',\n",
       " 'zoobike04',\n",
       " 'oscar2002',\n",
       " 'hola45',\n",
       " 'olyucskw52',\n",
       " 'megdam55',\n",
       " 'uoaef06gfqeb',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " '123477889a',\n",
       " 'sergius1964',\n",
       " 'pilatyj280',\n",
       " 'mdaffandi74',\n",
       " '1597535youssi',\n",
       " '3CgRg8DA1NQY1iEj',\n",
       " 'ab11223344',\n",
       " 'x0004534',\n",
       " 'MT766631',\n",
       " 'calcifer32',\n",
       " 'studenko123',\n",
       " 'z7zbgIDkzMQeHUd9',\n",
       " 'QWERTY0011',\n",
       " 'v8porwar3',\n",
       " 'krishna2',\n",
       " 'graciela2',\n",
       " 'purpledog1992',\n",
       " 'sandra0547',\n",
       " 'butisugo39',\n",
       " 's0xwym7h',\n",
       " '0847440744z',\n",
       " 'djngeyut2707',\n",
       " '3y6iwef2g6',\n",
       " 'u03kz6ez',\n",
       " 'faisal213',\n",
       " '10Erjrlmebup0n',\n",
       " 'senghong2009',\n",
       " 'clave08',\n",
       " '3vszncp4',\n",
       " 'sanki1',\n",
       " 'schalke04',\n",
       " 'evivad588',\n",
       " '1597535youssi',\n",
       " 'tomas7896',\n",
       " 'tuto0378',\n",
       " 'hodaq103',\n",
       " 'b98nwtpriyesh',\n",
       " 'XqMB7vDMzOQocAFV',\n",
       " 'killer5',\n",
       " '1A2Z3E4R',\n",
       " 'groster152',\n",
       " 'IjUcOtYqAwel725',\n",
       " 'mazdarx7',\n",
       " 'julie1989',\n",
       " 'lqksuym982',\n",
       " 'q0pv0fk',\n",
       " 's0xwym7h',\n",
       " 'lzhzad1989',\n",
       " 'kunyukbabi69',\n",
       " 'sebax2013',\n",
       " 'olmaz.',\n",
       " 'tia150979',\n",
       " 'juliana19',\n",
       " 'hosna1368',\n",
       " 'sw10d014',\n",
       " 'X34y2CzY5MACs6kp',\n",
       " 'iwaguh884',\n",
       " 'zoblin80',\n",
       " '147963asd',\n",
       " 'seng987321',\n",
       " 'aquhih220',\n",
       " 'kabrito1',\n",
       " '07dpv1127b',\n",
       " '07dpv1127b',\n",
       " 'bghuyku37',\n",
       " 'megdam55',\n",
       " 'aziz098765',\n",
       " 'jorge1489',\n",
       " 'asakapa22',\n",
       " 'mzhrmir786',\n",
       " 'mazdarx7',\n",
       " 'seller1',\n",
       " 'ezekiel720',\n",
       " 'gaymaids1',\n",
       " 'e667794c1d',\n",
       " 'cyborged69',\n",
       " '123456ts',\n",
       " 'ufoduvo540',\n",
       " 'papasito1991',\n",
       " 'kitty555',\n",
       " 'ubojig109',\n",
       " 'regodib479',\n",
       " 'gvczfel801',\n",
       " 'damyvo114',\n",
       " 'avanakit72',\n",
       " 'poluxyj32',\n",
       " 'housefly74',\n",
       " 'tuto0378',\n",
       " 'byeypb2',\n",
       " 'hola45',\n",
       " 'bang6k',\n",
       " 'b98nwtpriyesh',\n",
       " '215466kenyi',\n",
       " 'shH3t7TcyOQwKRLt',\n",
       " 'xW8-3w7-MFB-CKH',\n",
       " '123maxbala',\n",
       " 'robot425',\n",
       " 'AS0130066',\n",
       " 'd6VyrkFV6oblxNs5N8cW',\n",
       " '5874813o',\n",
       " 'sbl571017',\n",
       " 'just1n0k',\n",
       " 'artom111478',\n",
       " 'satrjcrj6',\n",
       " 'wuzyci421',\n",
       " 'oscar69',\n",
       " 'osimeytju12',\n",
       " 'parent777',\n",
       " 'afs34214',\n",
       " 'asgaliu11',\n",
       " 'GGmm26120904..',\n",
       " '7942vikas',\n",
       " 'change201',\n",
       " 'princ3sa',\n",
       " 'fudijep286',\n",
       " 'ineedyou23',\n",
       " 'graciela2',\n",
       " 'visi7k1yr',\n",
       " 'sbl571017',\n",
       " 'elabadmin1386',\n",
       " 'z888888',\n",
       " 'QWERTY0011',\n",
       " 'korea2010',\n",
       " 'acetita478',\n",
       " 'pacman23',\n",
       " 'fudijep286',\n",
       " '4lgYVfzk1MwuzHcn',\n",
       " '2652033abc',\n",
       " 'webhostv1t1n',\n",
       " 'paola1995',\n",
       " 'avanakit72',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'Iamthelegend1!',\n",
       " 'gracimir87',\n",
       " 'damyvo114',\n",
       " '9h7v4z91',\n",
       " 'p0lp0l',\n",
       " '3f5xd41l0ik7',\n",
       " 'rogyh820',\n",
       " '64959rodro',\n",
       " 'up8444',\n",
       " 'servbot88',\n",
       " 'polo2014',\n",
       " 'deryxi704',\n",
       " 'vmdo3i',\n",
       " '2GnTStTE4Mw4MTwv',\n",
       " 'mega0109',\n",
       " 'sysoja794',\n",
       " 'fk9qi21m',\n",
       " 'irivur594',\n",
       " 'bellsuki1',\n",
       " 'yllime123',\n",
       " 'moimoimoi9',\n",
       " 'wearehis7',\n",
       " 'pazzini24',\n",
       " 'obstacle25',\n",
       " '1qa2ws3ed4r',\n",
       " 'sofietou74',\n",
       " 'mel008',\n",
       " 'webhost08',\n",
       " 'just1n0k',\n",
       " 'weicat12',\n",
       " 'pukiw102',\n",
       " 'shotiko18',\n",
       " 'kah4544875',\n",
       " '68a2445667',\n",
       " 'm4r4hne',\n",
       " 'ass359',\n",
       " 'wbtdrieus345',\n",
       " '69556236gu',\n",
       " 'nokia6020',\n",
       " 'kong0074',\n",
       " 'jesmond26',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'szdectoj2',\n",
       " 'icap12',\n",
       " 'c3h8bkzr',\n",
       " 'examy624',\n",
       " 'emufat882',\n",
       " 'g3rappa',\n",
       " 'BsKbJHTY4NgesCOs',\n",
       " '1972vishara',\n",
       " 'pukiw102',\n",
       " 'goony01',\n",
       " 'bb9530',\n",
       " 'potatobus150',\n",
       " 'nello11',\n",
       " 'satelite31',\n",
       " 'natalia12',\n",
       " 'cesarmaio1',\n",
       " 'clumsy0619',\n",
       " '2010server',\n",
       " 'x57669',\n",
       " 'xve33ea',\n",
       " 'kino3434',\n",
       " 'kXzWOozU2MQ1Jv1h',\n",
       " 'caramelo9',\n",
       " 'rsuvxz08b',\n",
       " '1qa2ws3ed4rf',\n",
       " 'z888888',\n",
       " 'amandine666',\n",
       " 'growerz543',\n",
       " 'ts02521712',\n",
       " 'acetita478',\n",
       " 'xyws951753',\n",
       " '16731673ir',\n",
       " 'pilatyj280',\n",
       " '2652033abc',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " '72o0yzekib4',\n",
       " '238wofutUtIGyf',\n",
       " 'poseidon2011',\n",
       " 'aio42fv',\n",
       " 'rogama69',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'peluchin4',\n",
       " 'igejasy712',\n",
       " 'daylit9',\n",
       " 'x57669',\n",
       " 'cockw0mble',\n",
       " 'visi7k1yr',\n",
       " 'w9209640',\n",
       " 'ass359',\n",
       " 'hotdog20',\n",
       " 'faranumar91',\n",
       " 'yjuqseb416',\n",
       " 'jerusalem393',\n",
       " 'jbtcnd6',\n",
       " 'khurram_',\n",
       " 'ajyrew547',\n",
       " 'apther1940',\n",
       " 'hodaq103',\n",
       " 'apther1940',\n",
       " '27121995qw',\n",
       " 'nikolas369',\n",
       " 'tucagu356',\n",
       " 'josef0867',\n",
       " 'szdectoj2',\n",
       " 'elperro1',\n",
       " 'J0LcDWDc2NAVE8j3',\n",
       " 'wisal1234',\n",
       " 'amandine666',\n",
       " 'seeyouagain1',\n",
       " '1k9izx',\n",
       " 'smart95',\n",
       " 'senghong2009',\n",
       " 'juliana19',\n",
       " 'spl51190595',\n",
       " 'aslpls2009',\n",
       " 'cdann123',\n",
       " 'taurofive16',\n",
       " 'patri1973',\n",
       " 'keithar1',\n",
       " 'jbiz04h4',\n",
       " 'p@sslng2diword',\n",
       " 'ts02521712',\n",
       " 'kayal123',\n",
       " 'ekufite742',\n",
       " 'szdectoj2',\n",
       " 'sandra0547',\n",
       " 'frhnsvelhfr1',\n",
       " 'midgeman8505',\n",
       " 'juliel009',\n",
       " 'koabcswzt3',\n",
       " 'mega0109',\n",
       " 'r0cker',\n",
       " 'holamundo1',\n",
       " 'bgrvl80',\n",
       " 'just1n0k',\n",
       " 'yilmaz070',\n",
       " 'openup12',\n",
       " 'h3ndr4',\n",
       " 'bang6k',\n",
       " 'kjkjkj1',\n",
       " 'karl88',\n",
       " 'jekkmoeder>',\n",
       " 'czuodhj972',\n",
       " '847XagYxUHUXOW',\n",
       " 'poilkjmnb987',\n",
       " 'DTUQG5jU5MwmR1L9',\n",
       " 'jeeves123',\n",
       " 'intel1',\n",
       " 'mosad999',\n",
       " 'nelva20',\n",
       " 'pass0port',\n",
       " 'juliel009',\n",
       " 'jj46azbo',\n",
       " 'a110804032',\n",
       " 'tia150979',\n",
       " 'tim80327',\n",
       " 'GGmm26120904..',\n",
       " '1991vikash',\n",
       " 'laedbchsx687',\n",
       " 'avanakit72',\n",
       " 'housefly74',\n",
       " 'desmondkok21',\n",
       " 'webhost08',\n",
       " 'visi7k1yr',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669639, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_divide_char(inputs):\n",
    "    characters=[]\n",
    "    for i in inputs:\n",
    "        characters.append(i)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k', 'z', 'd', 'e', '5', '5', '7', '7']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_divide_char('kzde5577')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(tokenizer=word_divide_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669639, 136)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x02',\n",
       " '\\x04',\n",
       " '\\x05',\n",
       " '\\x06',\n",
       " '\\x08',\n",
       " '\\x0e',\n",
       " '\\x0f',\n",
       " '\\x10',\n",
       " '\\x16',\n",
       " '\\x17',\n",
       " '\\x18',\n",
       " '\\x19',\n",
       " '\\x1b',\n",
       " '\\x1c',\n",
       " '\\x1e',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x81',\n",
       " '\\x8d',\n",
       " '\\xa0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_document_vector=x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x136 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.56769226],\n",
       "        [0.        ],\n",
       "        [0.59110062],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.28576884],\n",
       "        [0.22095901],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.29185632],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.33564674],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document_vector.T.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(first_document_vector.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\u0002</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\u0004</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\u0005</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\u0006</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\b</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf\n",
       "\u0002    0.0\n",
       "\u0004    0.0\n",
       "\u0005    0.0\n",
       "\u0006    0.0\n",
       "\b    0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.591101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.567692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.335647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.291856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.285769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>;</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf\n",
       "7   0.591101\n",
       "5   0.567692\n",
       "z   0.335647\n",
       "k   0.291856\n",
       "d   0.285769\n",
       "..       ...\n",
       "<   0.000000\n",
       ";   0.000000\n",
       "9   0.000000\n",
       "8   0.000000\n",
       "   0.000000\n",
       "\n",
       "[136 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)  #splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535711, 136)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing various algorithms but can't apply as it will have less resources & it will take very much time (>20 min ) to perform all these stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as sl\n",
    "import sklearn.ensemble as se\n",
    "import sklearn.tree as tr\n",
    "import sklearn.neighbors as ne\n",
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classifier models\n",
    "models = []\n",
    "models.append(('LogisticRegression', sl.LogisticRegression()))\n",
    "models.append(('RandomForest', se.RandomForestClassifier(n_estimators=100, min_samples_leaf=10, random_state=1)))\n",
    "models.append(('Decision Tree', tr.DecisionTreeClassifier()))\n",
    "models.append(('KNN', ne.KNeighborsClassifier(n_neighbors = 5)))\n",
    "models.append(('SVM', svm.SVC()))\n",
    "models.append(('AdaBoost',se.AdaBoostClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "RandomForest\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
      "                       warm_start=False)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "KNN\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "SVM\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "AdaBoost\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for name, model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    print(name) \n",
    "    ##confusion metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(y_test,predictions)\n",
    "    print(cm)\n",
    "    #predict how our model is\n",
    "    from sklearn.metrics import accuracy_score,classification_report\n",
    "    print(accuracy_score(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print('\\n')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply logistic on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_class=LogisticRegression()\n",
    "log_class.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8175586882504032\n"
     ]
    }
   ],
   "source": [
    "print(log_class.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Multinomial logistic Regression as have data have 3 categories in outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8184546920733529\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')\n",
    "clf.fit(X_train, y_train) #training\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to do prediction for \"%@123abcd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X_predict=np.array([\"%@123abcd\"])\n",
    "X_predict=vectorizer.transform(X_predict)\n",
    "y_pred=log_class.predict(X_predict)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predictions on X-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred=log_class.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5266 12665    16]\n",
      " [ 3937 92993  2579]\n",
      " [   41  5196 11235]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8175586882504032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.29      0.39     17947\n",
      "           1       0.84      0.93      0.88     99509\n",
      "           2       0.81      0.68      0.74     16472\n",
      "\n",
      "    accuracy                           0.82    133928\n",
      "   macro avg       0.74      0.64      0.67    133928\n",
      "weighted avg       0.80      0.82      0.80    133928\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
